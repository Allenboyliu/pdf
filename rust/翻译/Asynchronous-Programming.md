## 目录

### 前言

### 第1部分：异步编程基础

#### 1. 并发与异步编程：详细概述

- **技术要求**
- 多任务处理的进化历程
- 非抢占式多任务
- 抢占式多任务
- 超线程
- 多核处理器
- 你真的是在写同步代码吗？
- 并发与并行
- 我使用的思维模型
- 让我们画出一些与进程经济学的平行关系
- 并发与I/O的关系
- 那操作系统提供的线程怎么办？
- 选择合适的参考框架
- 异步与并发
- 操作系统的角色
- 从操作系统的视角看并发
- 与操作系统合作
- 与操作系统通信
- CPU与操作系统
- 走进兔子洞
- CPU是如何防止我们访问不该访问的内存的？
- 难道我们不能直接在CPU中修改页表吗？
- 中断、固件和I/O
    - 简化概述
    - 中断
    - 固件

#### 总结


## 异步与并发

- 操作系统的角色
- 从操作系统的角度看并发
- 与操作系统合作
- 与操作系统通信
- CPU与操作系统
- 走进兔子洞
- CPU是如何防止我们访问不该访问的内存的？
- 难道我们不能直接在CPU中修改页表吗？
- 中断、固件和I/O
    - 简化概述
    - 中断
    - 固件

#### 总结

---

## 2. 编程语言如何建模异步程序流

- **定义**
- 线程
- 操作系统提供的线程
- 创建新线程需要时间
- 每个线程有自己的栈
- 上下文切换
- 调度
- 将异步操作与操作系统线程解耦的优点
- 示例
- 纤程和绿色线程
- 每个栈有固定的空间
- 上下文切换
- 调度
- 外部函数接口（FFI）
- 基于回调的方法
- 协程：承诺和未来
- 协程与async/await
- **总结**

---

## 3. 理解操作系统支持的事件队列、系统调用和跨平台抽象

- **技术要求**
- 运行Linux示例
- 为什么使用操作系统支持的事件队列？
- 阻塞I/O
- 非阻塞I/O
- 通过epoll/kqueue和IOCP进行事件排队
- 基于就绪的事件队列
- 基于完成的事件队列
- epoll, kqueue和IOCP
- 跨平台事件队列
- 系统调用、FFI和跨平台抽象
## 3. 理解操作系统支持的事件队列、系统调用和跨平台抽象

- **技术要求**
- 运行Linux示例
- 为什么使用操作系统支持的事件队列？
- 阻塞I/O
- 非阻塞I/O
- 通过epoll/kqueue和IOCP进行事件排队
- 基于就绪的事件队列
- 基于完成的事件队列
- epoll, kqueue和IOCP
- 跨平台事件队列
- 系统调用、FFI和跨平台抽象
    - 最低层次的抽象
    - 下一层次的抽象
    - 最高层次的抽象

#### 总结

---

## Part 2: 事件队列与绿色线程

### 4. 创建你自己的事件队列

- **技术要求**
- 设计与epoll简介
- 所有I/O操作都阻塞吗？
- ffi模块
- 位标志与位掩码
- 水平触发与边缘触发事件
- Poll模块
- 主程序
- **总结**

### 5. 创建我们自己的纤程

- **技术要求**
- 如何将仓库与本书一起使用
- 背景信息
    - 指令集、硬件架构与ABI
    - x86-64的System V ABI
    - 简要介绍汇编语言
    - 一个我们可以构建的示例
- 设置我们的项目
- Rust内联汇编宏简介
- 运行我们的示例
- 堆栈
    - 堆栈是什么样的？
    - 堆栈大小
- 实现我们自己的纤程
    - 实现运行时
    - Guard、skip和switch
## ABIs
- x86-64的System V ABI
- 汇编语言简要介绍
- 一个我们可以构建的示例
- 设置我们的项目
- Rust内联汇编宏简介
- 运行我们的示例
- 堆栈
    - 堆栈是什么样的？
    - 堆栈大小
- 实现我们自己的纤程
    - 实现运行时
    - Guard、skip和switch函数
- 完成的思考
- **总结**

---

## Part 3: Rust中的Futures与async/await

### 6. Rust中的Futures

- 什么是Future？
- Leaf Futures
- 非Leaf Futures
- 异步运行时的思维模型
- Rust语言和标准库的处理
- I/O与CPU密集型任务
- **总结**

### 7. 协程和async/await

- **技术要求**
- 无栈协程简介
- 手写协程的示例
- Futures模块
- HTTP模块
- 所有Future都必须是惰性的吗？
- 创建协程
- async/await
- coroutine/wait
- corofy——协程预处理器
- b-async-await——协程/等待转换示例
- c-async-await——并发Future
- 最后的思考
- **总结**

### 8. 运行时、Wakers和反应器-执行器模式

- **技术要求**
- 运行时简介以及为什么需要它们
- 反应器和执行器
- 改进我们的基本示例
- 设计
- 修改当前实现
- 创建一个合适的运行时
- 步骤1 - 改进我们的...
### 步骤 2 - 实现一个合适的执行器
### 步骤 3 - 实现一个合适的反应器
- 实验我们的新运行时
- 一个使用并发的示例
- 同时并行运行多个Future
- **总结**

---

### 9. 协程、自引用结构体与Pinning

- **技术要求**
- 改进我们的示例1 – 变量
- 设置基础示例
- 改进我们的基础示例
- 改进我们的示例2 – 引用
- 改进我们的示例3 – 这…不好…
- 发现自引用结构体
- 什么是move？
- Rust中的Pinning
- Pinning的理论
- 定义
- 固定到堆上
- 固定到栈上
- Pin投影与结构化Pinning
- 改进我们的示例4 – Pinning来救场
- future.rs
- http.rs
- Main.rs
- executor.rs
- **总结**

---

### 10. 创建你自己的运行时

- **技术要求**
- 设置我们的示例
- main.rs
- future.rs
- http.rs
- executor.rs
- reactor.rs
### 实验我们的运行时
- **异步Rust的挑战**
- 显式与隐式反应器实例化
- 人体工程学与效率及灵活性
- 每个人都同意的常见特性
- 异步的drop
- 异步Rust的未来
- **总结**

### 尾声

### 索引

### 你可能喜欢的其他书籍



特定章节的代码位于该章节的文件夹中（例如，ch01）。每个示例被组织为一个单独的 crate。示例名称前的字母指示了书中不同例子的展示顺序。例如，thea-runtime 示例在 b-reactor-executor 示例之前。这种方式使它们按时间顺序排列（至少在大多数系统上是默认的）。一些示例的版本后面带有 -bonus 后缀。这些版本将在书中提到，通常包含一个特定变体的示例，可能很有趣，但与当前主题并无重要关系。

下载示例代码文件
您可以从 GitHub 下载此书的示例代码文件，网址为 https://github.com/PacktPublishing/Asynchronous-Programming-in-Rust。如果代码有更新，它将在 GitHub 仓库中更新。我们还有其他代码包可供查看，来自我们丰富的图书和视频目录，网址为 https://github.com/PacktPublishing/。请查阅！

使用的约定
本书中使用了一些文本约定。

文本中的代码：指文本中的代码词、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟网址、用户输入和 Twitter 帐号。示例：“所以，现在我们创建了自己的 async 运行时，使用 Rust 的 Futures、Waker、Context 和 async/await。”

代码块的格式如下所示：

rust
复制代码

pub trait Future {
    type Output;
    fn poll(&mut self) -> PollState<Self::Output>;
}
引起您注意的代码块的特定部分，相关行或项目会加粗显示：

rust
复制代码

struct Coroutine0 {
    stack: Stack0,
    state: State0,
}
任何命令行输入或输出格式如下：

复制代码

$ cargo run
小贴士或重要说明
以这种方式出现。

联系我们
我们欢迎读者的反馈。

一般反馈：如果您对本书的任何方面有疑问，请通过电子邮件联系我们，地址是 customercare@packtpub.com，并在邮件主题中提及书名。
勘误：虽然我们已尽一切努力确保内容的准确性，但错误确实会发生。如果您在本书中发现错误，我们将非常感激您向我们报告。请访问 www.packtpub.com/support/errata 并填写表格。
盗版：如果您在互联网上发现我们作品的任何非法复制品，请向我们提供位置地址或网站名称。请通过 copyright@packt.com 联系我们，并提供材料的链接。
有意成为作者：如果您对某个主题有专业知识，并且有兴趣写作或贡献一本书，请访问 authors.packtpub.com。
分享您的想法
阅读完《Rust 中的异步编程》后，我们很想听听您的想法！请点击这里直接访问本书的 Amazon 评价页面并分享您的反馈。您的评价对我们和技术社区都很重要，将帮助我们确保提供卓越质量的内容。

下载本书的免费 PDF 副本
感谢您购买本书！您是否喜欢随身阅读，但无法随身携带纸质书籍？您的电子书购买是否与您选择的设备不兼容？别担心，现在每本 Packt 书籍都可以免费获得无 DRM 的 PDF 版本。

随处随在，在您选择的任何设备上阅读。可以直接在应用程序中搜索、复制和粘贴您喜欢的技术书籍中的代码。这些好处不止于此，您还可以独家获得每日发送至您邮箱的折扣、通讯和极好的免费内容。

获取福利的简单步骤
扫描二维码或访问以下链接。

第一部分：异步编程基础
在本部分中，您将获得对并发和异步编程的全面介绍。我们还将探索各种编程语言用于建模异步性的技术，审视其中最流行的技术，并涵盖与每种技术相关的一些优缺点。最后，我们将解释操作系统支持的事件队列的概念，如 epoll、kqueue 和 IOCP，详细说明如何使用系统调用与操作系统进行交互，并解决创建跨平台抽象（如 mio）时遇到的挑战。本节包含以下章节：

第1章：并发与异步编程：详细概述
第2章：编程语言如何建模异��程序流
第3章：理解操作系统支持的事件队列、系统调用及跨平台抽象
1. 并发与异步编程：详细概述
异步编程是许多程序员认为令人困惑的话题之一。你会觉得自己似乎理解了它，然而随后却意识到这一领域比你想象的要复杂得多。如果你参与讨论，听足够多的演讲，并在互联网上阅读关于该主题的内容，你可能也会看到一些似乎互相矛盾的说法。至少，这描述了我第一次接触这个主题时的感受。

造成这种困惑的原因往往是缺乏上下文，或者作者在没有明确说明的情况下假定了特定的上下文，同时与并发和异步编程相关的术语相对定义较差。

在本章中，我们将覆盖很多内容，并将内容分为以下主要主题：

异步历史
并发与并行
操作系统与 CPU
中断、固件和 I/O
本章的性质较为总体，并不专门关注 Rust 或任何特定的编程语言，但这是我们需要了解的背景信息，以确保大家在接下来的讨论中有相同的基础。好处是，这些知识在无论使用何种编程语言时都是有用的。在我看来，这一事实也使得本章成为本书中最有趣的章节之一。

本章中的代码不多，因此我们轻松开始。现在正是泡一杯茶、放松身心的时候，因为我们将开始这段共同的旅程。

技术要求
所有示例将用 Rust 编写，您有两种选择来运行这些示例：

在 Rust Playground 上编写和运行我们将写的示例
在您的机器上安装 Rust 并本地运行示例（推荐）
阅读本章的理想方式是克隆附带的仓库（[https://github.com/PacktPublishing/Asynchronous-Programming-in-Rust/tree/main/ch01/a-](https://github.com/PacktPublishing/Asynchronous-Programming-in-Rust/tree/main/ch01/a-））。

替代方案4 - 使用两个酒保的并行和异步任务执行
如果你雇佣两个酒保，并要求他们执行替代方案3中描述的工作，但有一个变化：允许他们互相“抢”任务，这样酒保1可以开始倒酒并将啤酒放下静置，而酒保2可以在酒保1忙于倒新订单时进行加满和服务。这样，两位酒保很少会同时忙于工作，因为正在进行的啤酒在准备好时可以及时加满和服务。几乎所有的订单都在最短的时间内完成并服务，让顾客能更快地带着啤酒离开酒吧，并为想要下新订单的顾客腾出空间。

这样，你可以进一步提高吞吐量。尽管仍无法达到理论最大值，但你会非常接近。在开业之夜，你意识到酒保们每小时处理230个订单，总吞吐量达到每小时460瓶啤酒。收入看起来不错，顾客们很高兴，成本保持在最低水平，而你则是这个世界上最奇怪酒吧（不过是个极其高效的酒吧）的一位快乐管理者。

关键要点
并发是更加明智地工作的一种方式。并行则是向问题投入更多资源的一种方式。

并发及其与 I/O 的关系
正如你从我 até 目前为止的写作中可以理解的那样，编写异步代码通常在需要聪明地充分利用你的资源时更有意义。

如果你编写一个努力解决问题的程序，通常并发就没有什么帮助。这正是并行发挥作用的地方，因为如果你能将问题拆分成可以并行处理的部分，它就为你提供了一种投放更多资源的方式。考虑下面这两种并发的不同用例：

当执行 I/O 时，你需要等待某些外部事件发生。
当你需要分散注意力，防止一个任务等待过久。
第一个是经典的 I/O 示例：你必须等待网络调用、数据库查询或其他事情发生，才能推进任务。然而，你有许多任务要做，所以与你其等着的做法是继续在其他地方工作，定期检查任务是否准备好推进，或确保你会在任务准备好时收到通知。

第二个是当有用户界面时常见的情况。假设你只有一个核心。你如何确保在执行其他密集 CPU 任务时，让整个用户界面不会变得无响应呢？你可以每16毫秒停止你正在做的任何任务，运行更新用户界面的任务，然后再恢复你之前的工作。这样，你每秒需停止并恢复任务60次，但你也会拥有一个全响应的用户界面，刷新率约为60赫兹。

操作系统提供的线程呢？
在本书后面讨论处理 I/O 的策略时，我们将更深入地讨论线程，但我在这里也会提到它们。使用操作系统线程来理解并发的一个挑战是，它们似乎被映射到核心上。尽管大多数操作系统会尽量把一个线程映射到一个核心，直到线程数量等于核心数量，但这并不一定是一个正确的思维模型。

一旦我们创建的线程数量超过核心数量，操作系统将会在我们的线程之间切换，并使用其调度程序并发处理每个线程，为每个线程提供一些运行时间。你还必须考虑到你的程序并不是唯一在系统上运行的程序。其他程序也可能会生成多个线程，这意味着线程的数量将远远超过 CPU 上的核心数。

因此，线程可以是一种并行执行任务的手段，但它们也可以是一种实现并发的手段。

正确的参考框架
关于并发的最后一部分，它需要在某种参考框架中定义。

当你编写从你的角度来看完美同步的代码时，停下来想一想，从操作系统的角度来看那是什么样子。操作系统可能根本不会从头到尾运行你的代码。它可能会多次停止和恢复你的进程。CPU 可能在你认为它只专注于你的任务时会被中断并处理一些输入。

因此，同步执行只是一个幻觉。但从你作为程序员的角度来看，它并不是，这一点非常重要：

当我们讨论并发而不提供任何其他上下文时，我们使用你作为程序员和你的代码（你的进程）作为参考框架。如果你在思考并发时没有牢记这一点，事情很快就会变得混乱。

与操作系统的通信
与操作系统的通信是通过我们称之为系统调用（syscall）的机制实现的。我们需要知道如何进行系统调用，并理解当我们想与操作系统合作和沟通时，这为何如此重要。我们还需要了解我们日常使用的基本抽象如何在后台使用系统调用。我们将在第3章进行详细讲解，所以现在先简要介绍一下。

系统调用使用操作系统提供的公共 API，这样我们在“用户空间”编写的程序就可以与操作系统通信。大多数情况下，这些调用对于我们程序员来说已被我们使用的语言或运行时抽象了。

现在，一个系统调用是一个与您正在通信的内核特有的示例，但 UNIX 系列的内核有许多相似之处。UNIX 系统通过 libc 暴露这一点。而 Windows 则使用自己的 API，通常称为 WinAPI，它的操作方式与基于 UNIX 的系统可能有很大的不同。通常，有一种方法可以实现相同的功能。在功能方面，您可能不会注意到太大的差异，但正如我们稍后看到的，尤其是当我们深入了解 epoll、kqueue 和 IOCP 的工作原理时，它们在实现这些功能的方式上可以存在很大差异。

然而，系统调用并不是我们与操作系统交互的唯一方式，接下来的部分我们将看到这一点。

CPU 与操作系统
CPU 是否与操作系统合作？如果在我第一次认为我理解程序如何工作时问我这个问题，我很可能会回答“否”。我们在 CPU 上运行程序，只要知道怎么做，就可以随心所欲。但首先，我并没有认真思考这个问题，除非你了解 CPU 和操作系统是如何协同工作的，否则很难确切知道。

让我意识到我错得很离谱的是一段类似您即将看到的代码。如果您觉得 Rust 中的内联汇编看起来陌生且令人困惑，请暂时不用担心。我们将在本书稍后进行适当的内联汇编介绍。我会逐行解释以下代码，直到您对语法更熟悉为止：

仓库参考： ch01/ac-assembly-dereference/src/main.rs

rust
复制代码

fn main() {
    let t = 100;
    let t_ptr: *const usize = &t;
    let x = dereference(t_ptr);
    println!("{}", x);
}

fn dereference(ptr: *const usize) -> usize {
    let mut res: usize;
    unsafe {
        asm!("mov {0}, [{1}]", out(reg) res, in(reg) ptr)
    };
    res
}
您看到的正是用汇编编写的间接引用函数。mov {0}, [{1}] 这行需要一些解释。{0} 和 {1} 是模板，用于告诉编译器我们正在指代 out(reg) 和 in(reg) 表示的寄存器。数字只是索引，因此如果我们有更多的输入或输出，它们将编号为 {2}、{3} 等。由于我们只指定了 reg 而不是特定寄存器，我们让编译器选择它想使用的寄存器。

mov 指令指示 CPU 从 ptr 指向的内存位置读取前 8 个字节（如果我们在 64 位计算机上），并将其放置在 {0} 所代表的寄存器中。方括号 [] 将 instruct CPU 将该寄存器中的数据视为内存地址，而不是简单地将内存地址复制到 {0}。它会提取该内存位置上的内容并移动过去。

无论如何，我们在这里只是向 CPU 编写指令。没有标准库，没有系统调用；只是原始指令。操作系统根本没有涉及到这个间接引用函数，对吧？

如果您运行这个程序，您会得到期望的结果：100。

现在，如果您保留间接引用函数，但用一个创建指向 99999999999999 地址（我们知道这个地址是无效的）的指针的函数替换 main 函数，代码变为：

rust
复制代码

fn main() {
    let t_ptr = 99999999999999 as *const usize;
    let x = dereference(t_ptr);
    println!("{}", x);
}
现在，如果我们运行它，会得到以下结果：

在 Linux 上的结果：

复制代码

Segmentation fault (core dumped)
在 Windows 上的结果：

复制代码

error: process didn't exit successfully: `target\debug\ac-assembly-dereference.exe` (exit code: 0xc0000005, STATUS_ACCESS_VIOLATION)
我们得到了段错误。这并不令人惊讶，但正如您可能注意到的那样，我们在不同平台上得到的错误是不同的。显然，操作系统以某种方式参与了这一过程。让我们看看这里实际上发生了什么。


走进兔子洞
事实证明，操作系统与 CPU 之间有着大量的合作，但这可能并不是你天真想象的那样。许多现代 CPU 提供了一些操作系统所需的基本基础设施。这些基础设施为我们提供了我们所期望的安全性和稳定性。实际上，大多数高级 CPU 提供的选项远比 Linux、BSD 和 Windows 等操作系统实际使用的要多得多。

这里我想特别提及两个方面：

CPU 如何阻止我们访问不应该访问的内存。
CPU 如何处理异步事件，例如 I/O。
我们将在这里讨论第一个问题，而第二个问题将在下一部分讨论。

CPU 如何防止我们访问不应该访问的内存？
正如我提到的，现代 CPU 架构通过设计定义了一些基本概念。以下是一些示例：

虚拟内存
页表
页故障
异常
特权等级
具体的实现方式会因具体的 CPU 而有所不同，因此我们在此将其概括性处理。

大多数现代 CPU 都配备了内存管理单元（MMU）。这一部分有时甚至与 CPU 同一块晶圆上制造。MMU 的任务是将我们在程序中使用的虚拟地址转换为物理地址。

当操作系统启动一个进程（如我们的程序）时，它会为我们的进程设置一个页表，并确保 CPU 上的一个特殊寄存器指向这个页表。

现在，当我们尝试间接引用 t_ptr 时，这个地址最终会被发送到 MMU 进行转换，MMU 会在页表中查找，并将其转换为内存中的物理地址，以便它可以提取数据。

在第一个情况下，它将指向我们栈中的一个内存地址，该地址保存着值 100。当我们输入 99999999999999 并请求提取存储在该地址的内容（这就是间接引用的功能）时，它在页表中寻找对应的翻译，却找不到。

此时，CPU 将此视为页故障。

在启动时，操作系统向 CPU 提供了一个中断描述符表。这个表具有预定义的格式，操作系统为 CPU 可能遇到的预定义条件提供处理程序。由于操作系统提供了指向处理页故障的函数的指针，当我们尝试间接引用 99999999999999 时，CPU 会跳转到该函数，从而将控制权交给操作系统。

操作系统随后会为我们打印一条友好的消息，告诉我们遇到了它所称的段错误（segmentation fault）。因此，这条消息可能会根据您运行代码的操作系统而有所不同。

我们不能直接更改 CPU 中的页表吗？
这时，特权等级就派上用场了。大多数现代操作系统采用两个环级别：环 0（内核空间）和环 3（用户空间）。

大多数 CPU 拥有比现代操作系统使用的更多环的概念
这是出于历史原因，这也是为什么使用环 0 和环 3（而不是环 1 和环 2）的原因。每个页表中的条目都有关于其额外信息。其中包含有关其所属环的信息。这些信息在您的操作系统启动时设置。

在环 0 中执行的代码几乎具有对外部设备和内存的无限制访问，可以自由更改提供硬件层面安全性的寄存器。而您在环 3 中编写的代码通常对 I/O 和某些 CPU 寄存器（以及指令）具有极其有限的访问权限。试图从环 3 中发出指令或设置寄存器以更改页表将被 CPU 阻止。CPU 会将此视为异常，并跳转到操作系统提供的该异常的处理程序。

这也是您别无选择，只能与操作系统合作并通过系统调用处理 I/O 任务的原因。如果不是这样的情况，系统将不会非常安全。

总结
简而言之：是的，CPU 和操作系统之间有很大的合作。大多数现代桌面 CPU 的设计考虑到了操作系统，因此它们提供了操作系统在启动时依附于的钩子和基础设施。当操作系统生成一个进程时，它也会设置其特权级别，确保普通进程保持在其定义的边界内，以维持稳定性和安全性。

中断、固件和 I/O
我们即将结束本书中的一般计算机科学主题，并将很快开始探索如何走出兔子洞。

这一部分试图将所有内容结合起来，观察整个计算机如何作为一个系统来处理 I/O 和并发。

让我们开始吧！

简化概述
让我们看一下我们从网络卡读取数据时的一些步骤。

中断
如您所知，存在两种类型的中断：

硬件中断
软件中断
它们在本质上是非常不同的��

硬件中断
硬件中断是通过在 IRQ 上发送电信号来产生的。这些硬件线路直接向 CPU 发出信号。

软件中断
软件中断则是由软件发出的，而不是硬件发出的。与硬件中断一样，CPU 会跳转到中断描述符表（IDT），并运行指定中断的处理程序。

固件
固件在我们大多数人眼中并没有得到太多关注；然而，它是我们生活中至关重要的一部分。固件在各种硬件上运行，并以各种奇怪且特殊的方式使我们所编程的计算机正常工作。

现在，固件需要微控制器才能工作。甚至 CPU 也有使其正常工作的固件。这意味着在我们的系统中，存在比我们编程所针对的核心更多的小“CPU”。

为什么这很重要？
好吧，您还记得并发是关于效率的，对吗？既然系统中已有许多 CPU/微控制器在为我们工作，我们写代码时的一个关注点就是不要重复或复制这些工作。

如果网络卡有固件不断检查是否有新数据到达，那么如果让我们的 CPU 也不断检查是否有新数据到达，那将非常浪费。更好的方式是偶尔检查一次，或者更好的是，当数据到达时获得通知。

总结
本章涵盖了很多内容，因此您做得很好，完成了这些基础工作。我们从历史角度了解了 CPU 和操作系统如何演变，以及非抢占式和抢占式多任务之间的区别。我们讨论了并发与并行之间的差异，谈论了操作系统的角色，并了解到系统调用是我们与宿主操作系统交互的主要方式。您还看到了 CPU 和操作系统通过设计为 CPU 一部分的基础设施进行合作的方式。

最后，我们查看了一张关于发出网络调用时会发生什么的图。您知道我们至少有三种不同的方法来处理 I/O 调用执行所需的时间，而我们必须决定以哪种方式来处理这个等待时间。

这一部分涵盖了我们所需的大部分背景信息，以确保在继续之前我们有相同的定义和概述。随着我们在书中的深入，将会有更多的详细内容，而下一章的第一个主题是编程语言如何通过线程、协程和期货模型化异步程序流程。


2. 编程语言如何模型化异步程序流
在上一章中，我们对异步程序流、并发和并行进行了概述。在本章中，我们将缩小范围。具体来说，我们将探讨编程语言和库中模型化并发的不同方式。

需要记住的是，线程、期货、纤维、协程、承诺等都是抽象，它们为我们提供了一种模型化异步程序流的方式。它们各有优缺点，但共同的目标是为程序员提供一种易于使用（同样重要的是，不容易误用）、高效且富有表现力的方式，以创建以非顺序且往往不可预测的方式处理任务的程序。

在这里，缺乏准确的定义同样普遍；许多术语的名称源于某个特定时间的具体实现，但后来被赋予了更普遍的意义，涵盖了同一事物的不同实现和变种。

我们将首先通过它们的相似性来对不同的抽象进行分组，然后再讨论每种抽象的优缺点。我们还会介绍一些将在全书中使用的重要定义，并详细讨论操作系统线程。

我们讨论的主题相对抽象且复杂，所以如果您不能立即理解所有内容，也不要感到沮丧。随着我们在书中的深入，通过处理一些示例，您会逐渐习惯不同的术语和技术，更多的知识会变得清晰。

具体而言，将涵盖以下主题：

定义
操作系统提供的线程
绿色线程/栈满协程/纤维
基于回调的方法
承诺、期货以及 async/await
定义
我们可以将并发操作的抽象大致分为两类：

协作式：这些任务自愿让出控制权，要么通过明确的让步，要么通过调用一个在另一项操作完成之前无法进一步推进时挂起任务的函数（例如发起网络调用）。这些任务通常会让出控制权给某种调度程序。Rust 和 JavaScript 中的 async/await 生成的任务就是这类任务的例子。

非协作式：这些任务不一定自愿让出控制权。在这样的系统中，调度程序必须能够抢先控制正在运行的任务，这意味着调度程序可以停止任务并控制 CPU，即使该任务能够继续工作并推进。操作系统线程和 Goroutines（自 Go 版本 1.14 之后）就是这类任务的例子。

嵌入式系统
嵌入式系统如今比以往任何时候都更为普遍。这种硬件可能没有足够的资源运行操作系统，如果有，它们可能会使用一种与您的需求高度契合的根本不同的操作系统，因为这些系统往往不那么通用，而具有更专门化的特点。

它们对线程的支持和调度特性可能与您在像 Windows 或 Linux 这样的操作系统中所习惯的不同。由于涵盖所有不同设计将是一本独立的书籍，我们将局限于讨论在流行的桌面和服务器 CPU 上运行的 Windows 和 Linux 系统中的线程。

操作系统线程很容易实现和使用。我们只需让操作系统为我们处理所有事务。我们通过为每个要完成的任务生成一个新的操作系统线程，并像平常一样编写代码来实现这一点。我们处理并发的运行时环境就是操作系统本身。除了这些优点之外，您还可以免费获得并行性。然而，直接管理并行性和共享资源也会带来一些缺点和复杂性。

创建新线程所需时间
创建一个新的操作系统线程涉及一些记录和初始化开销，因此虽然在相同进程中切换两个现有线程相当快速，但创建新线程和丢弃不再使用的线程会涉及耗时的工作。如果系统需要创建和丢弃大量线程，这一额外的工作将限制吞吐量。如果有大量的小任务需要并发处理，这在处理大量 I/O 时往往是个问题。

每个线程都有自己的栈
我们将在本书后面详细介绍栈，但现在知道它们占据固定大小的内存就足够了。每个操作系统线程都有自己独立的栈，即使许多系统允许配置这个大小，它们仍然是固定的，无法增长或缩小。毕竟，栈溢出就是由此造成的，如果您将其配置得过小而无法满足正在运行的任务，就会成为一个问题。

如果我们有许多只需要少量栈空间的小任务，但我们预留了比所需更多的栈空间，那么我们将占用大量内存，并可能耗尽可用内存。

上下文切换
正如您现在所知道的，线程和调度程序是紧密相连的。上下文切换发生在 CPU 停止执行一个线程并转到另一个线程时。尽管这个过程经过高度优化，但它仍涉及到存储和恢复寄存器状态，这需要时间。每次您让出控制权给操作系统调度程序时，它可以选择在该 CPU 上调度一个来自不同进程的线程。

您看到，这些系统创建的线程属于一个进程。当您启动一个程序时，它启动一个进程，该进程创建至少一个初始线程，并在该线程中执行您编写的程序。每个进程可以生成多个共享同一地址空间的线程。这意味着在同一进程内的线程可以访问共享内存，并可以访问相同的资源，例如文件和文件句柄。

这样的结果是，当操作系统通过停止一个线程并恢复同一进程中的另一个线程来进行上下文切换时，它不需要保存和恢复与该进程相关的所有状态，仅需保存与该线程相关的状态。

另一方面，当操作系统从与一个进程相关的线程切换到与另一个进程相关的线程时，新进程将使用不同的地址空间，操作系统需要采取措施确保进程“A”不会访问属于进程“B”的数据或资源。如果不这样做，系统的安全性将受到威胁。

因此，结果是可能需要冲刷缓存，并且可能需要保存和恢复更多的状态。在高并发的系统中，当负载增加时，这些上下文切换可能会额外耗时，从而在频繁发生时以某种不可预测的方式限制吞吐量。

调度
操作系统可以以您可能不期望的方式调度任务，每当您让位于操作系统时，您就会与系统上所有其他线程和进程排在同一个队列中。

此外，由于没有保证线程会在与其离开时相同的 CPU 核心上恢复执行，或者两个任务不会并行运行并尝试访问相同的数据，因此您需要同步数据访问，以防止数据竞争和与多核编程相关的其他陷阱。

作为一门语言，Rust 将帮助您防止许多这些陷阱，但同步数据访问将需要额外的工作，并增加此类程序的复杂性。我们常常说，使用操作系统线程来处理并发为我们免费提供了并行性，但在增加复杂性和对正确数据访问同步的需求方面，这并不是免费的。



线程与调度器的关系
如您现在所知，线程和调度器是紧密相连的。上下文切换发生在 CPU 停止执行一个线程并转向另一个线程时。尽管这个过程经过高���优化，但它仍涉及到存储和恢复寄存器状态，这需要时间。每当您将控制权让给操作系统调度程序时，它可以选择在该 CPU 上调度不同进程中的一个线程。

您会看到，这些系统创建的线程属于一个进程。当您启动一个程序时，它会启动一个进程，该进程创建至少一个初始线程，并在该线程中执行您编写的程序。每个进程可以生成多个共享同一地址空间的线程。

这意味着，同一进程内的线程可以访问共享内存，并可以访问相同的资源，例如文件和文件句柄。这样做的一个后果是，当操作系统通过停止一个线程并恢复同一进程中的另一个线程来进行上下文切换时，它不需要保存和恢复与该进程相关的所有状态，只需保存与该线程相关的状态。

另一方面，当操作系统从一个进程相关的线程切换到另一个进程相关的线程时，新进程将使用不同的地址空间，操作系统需要采取措施确保进程“A”不会访问属于进程“B”的数据或资源。如果不这样做，系统将是不安全的。

因此，缓存可能需要被清空，并且可能需要保存和恢复更多的状态。在高并发的系统负载下，这些上下文切换可能会额外耗时，从而在频繁发生时以某种不可预测的方式限制吞吐量。

调度
操作系统可以以您可能不期望的方式调度任务，每当您向操作系统让出控制权时，您会与系统上所有其他线程和进程排在同一个队列中。

此外，由于没有保证线程会在与其离开时相同的 CPU 核心上恢复执行，或者两个任务不会同时运行并尝试访问相同的数据，您需要同步数据访问，以防止数据竞争和与多核编程相关的其他陷阱。

作为一门语言，Rust 将帮助您防止许多这些陷阱，但同步数据访问将需要额外的工作，并增加此类程序的复杂性。我们常常说，使用操作系统线程来处理并发为我们提供了免费的并行性，但在增加复杂性和对正确数据访问同步的需求方面，这并不是免费的。

将异步操作与操作系统线程解耦的优势
将异步操作与线程的概念解耦有很多好处。首先，使用操作系统线程来处理并发要求我们使用本质上是操作系统抽象的手段来表示我们的任务。

拥有一个单独的抽象层来表示并发任务让我们自由选择如何处理并发操作。如果我们在 Rust 中创建一个用于并发操作的抽象，比如期货（future）、在 JavaScript 中的承诺（promise）或 Go 中的协程（goroutine），那么由运行时的实现者决定如何处理这些并发任务。

运行时可以简单地将每个并发操作映射到一个操作系统线程，或者使用纤维/绿色线程或状态机来表示任务。编写异步代码的程序员如果底层实现发生变化可能不需要对其代码进行任何更改。

理论上，相同的异步代码可以在没有操作系统的微控制器上用来处理并发操作，只要有相应的运行时即可。

总结
使用操作系统提供的线程来处理并发具有以下优势：

易于理解
易于使用
任务之间的切换相对快速
免费获得并行性
然而，它们也有一些缺点。
将异步操作与线程的概念解耦具有许多好处。首先，使用操作系统线程来处理并发要求我们使用本质上是操作系统抽象的手段来表示我们的任务。

拥有一个单独的抽象层来表示并发任务让我们自由选择如何处理并发操作。如果我们创建一个并发操作的抽象，例如 Rust 中的期货（future）、JavaScript 中的承诺（promise）或 Go 中的协程（goroutine），那么如何处理这些并发任务的决定将取决于运行时的实现者。

运行时可以简单地将每个并发操作映射到一个操作系统线程，也可以使用纤维/绿色线程或状态机来表示任务。编写异步代码的程序员在底层实现发生变更时不一定需要对其代码进行任何修改。

理论上，相同的异步代码可以在没有操作系统的微控制器上用于处理并发操作，只要有适用的运行时即可。

总结
使用操作系统提供的线程来处理并发具有以下优势：

容易理解
易于使用
任务之间的切换相对快速
免费获得并行性
然而，它们也有一些缺点：

操作系统级线程通常具有较大的栈。如果有许多任务同时等待（例如在负载很重的网络服务器中），您会很快耗尽内存。
上下文切换可能会很昂贵，并且由于将所有调度都交给操作系统，您可能会获得不可预测的性能。操作系统需要处理的事务非常多，可能无法像您希望的那样快速切换回您的线程。
它与操作系统抽象紧密耦合。在某些系统上，这可能不是一个可选项。
示例
由于在本书中我们不会花更多时间讨论操作系统线程，因此我们将通过一个简短的示例来展示它们是如何使用的。



ch02/aa-os-threads use std::thread::{self, sleep}; fn main() {     println!("So, we start the program here!");     let t1 = thread::spawn(move || {         sleep(std::time::Duration::from_millis(200));         println!("The long running tasks finish last!");     }); 
    let t2 = thread::spawn(move || {         sleep(std::time::Duration::from_millis(100));         println!("We can chain callbacks...");         let t3 = thread::spawn(move || {             sleep(std::time::Duration::from_millis(50));             println!("...like this!");         });         t3.join().unwrap();     });     println!("The tasks run concurrently!");     t1.join().unwrap();     t2.join().unwrap(); }


    
