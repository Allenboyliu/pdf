## 目录

### 前言

### 第1部分：异步编程基础

#### 1. 并发与异步编程：详细概述

- **技术要求**
- 多任务处理的进化历程
- 非抢占式多任务
- 抢占式多任务
- 超线程
- 多核处理器
- 你真的是在写同步代码吗？
- 并发与并行
- 我使用的思维模型
- 让我们画出一些与进程经济学的平行关系
- 并发与I/O的关系
- 那操作系统提供的线程怎么办？
- 选择合适的参考框架
- 异步与并发
- 操作系统的角色
- 从操作系统的视角看并发
- 与操作系统合作
- 与操作系统通信
- CPU与操作系统
- 走进兔子洞
- CPU是如何防止我们访问不该访问的内存的？
- 难道我们不能直接在CPU中修改页表吗？
- 中断、固件和I/O
    - 简化概述
    - 中断
    - 固件

#### 总结


## 异步与并发

- 操作系统的角色
- 从操作系统的角度看并发
- 与操作系统合作
- 与操作系统通信
- CPU与操作系统
- 走进兔子洞
- CPU是如何防止我们访问不该访问的内存的？
- 难道我们不能直接在CPU中修改页表吗？
- 中断、固件和I/O
    - 简化概述
    - 中断
    - 固件

#### 总结

---

## 2. 编程语言如何建模异步程序流

- **定义**
- 线程
- 操作系统提供的线程
- 创建新线程需要时间
- 每个线程有自己的栈
- 上下文切换
- 调度
- 将异步操作与操作系统线程解耦的优点
- 示例
- 纤程和绿色线程
- 每个栈有固定的空间
- 上下文切换
- 调度
- 外部函数接口（FFI）
- 基于回调的方法
- 协程：承诺和未来
- 协程与async/await
- **总结**

---

## 3. 理解操作系统支持的事件队列、系统调用和跨平台抽象

- **技术要求**
- 运行Linux示例
- 为什么使用操作系统支持的事件队列？
- 阻塞I/O
- 非阻塞I/O
- 通过epoll/kqueue和IOCP进行事件排队
- 基于就绪的事件队列
- 基于完成的事件队列
- epoll, kqueue和IOCP
- 跨平台事件队列
- 系统调用、FFI和跨平台抽象
## 3. 理解操作系统支持的事件队列、系统调用和跨平台抽象

- **技术要求**
- 运行Linux示例
- 为什么使用操作系统支持的事件队列？
- 阻塞I/O
- 非阻塞I/O
- 通过epoll/kqueue和IOCP进行事件排队
- 基于就绪的事件队列
- 基于完成的事件队列
- epoll, kqueue和IOCP
- 跨平台事件队列
- 系统调用、FFI和跨平台抽象
    - 最低层次的抽象
    - 下一层次的抽象
    - 最高层次的抽象

#### 总结

---

## Part 2: 事件队列与绿色线程

### 4. 创建你自己的事件队列

- **技术要求**
- 设计与epoll简介
- 所有I/O操作都阻塞吗？
- ffi模块
- 位标志与位掩码
- 水平触发与边缘触发事件
- Poll模块
- 主程序
- **总结**

### 5. 创建我们自己的纤程

- **技术要求**
- 如何将仓库与本书一起使用
- 背景信息
    - 指令集、硬件架构与ABI
    - x86-64的System V ABI
    - 简要介绍汇编语言
    - 一个我们可以构建的示例
- 设置我们的项目
- Rust内联汇编宏简介
- 运行我们的示例
- 堆栈
    - 堆栈是什么样的？
    - 堆栈大小
- 实现我们自己的纤程
    - 实现运行时
    - Guard、skip和switch
## ABIs
- x86-64的System V ABI
- 汇编语言简要介绍
- 一个我们可以构建的示例
- 设置我们的项目
- Rust内联汇编宏简介
- 运行我们的示例
- 堆栈
    - 堆栈是什么样的？
    - 堆栈大小
- 实现我们自己的纤程
    - 实现运行时
    - Guard、skip和switch函数
- 完成的思考
- **总结**

---

## Part 3: Rust中的Futures与async/await

### 6. Rust中的Futures

- 什么是Future？
- Leaf Futures
- 非Leaf Futures
- 异步运行时的思维模型
- Rust语言和标准库的处理
- I/O与CPU密集型任务
- **总结**

### 7. 协程和async/await

- **技术要求**
- 无栈协程简介
- 手写协程的示例
- Futures模块
- HTTP模块
- 所有Future都必须是惰性的吗？
- 创建协程
- async/await
- coroutine/wait
- corofy——协程预处理器
- b-async-await——协程/等待转换示例
- c-async-await——并发Future
- 最后的思考
- **总结**

### 8. 运行时、Wakers和反应器-执行器模式

- **技术要求**
- 运行时简介以及为什么需要它们
- 反应器和执行器
- 改进我们的基本示例
- 设计
- 修改当前实现
- 创建一个合适的运行时
- 步骤1 - 改进我们的...
### 步骤 2 - 实现一个合适的执行器
### 步骤 3 - 实现一个合适的反应器
- 实验我们的新运行时
- 一个使用并发的示例
- 同时并行运行多个Future
- **总结**

---

### 9. 协程、自引用结构体与Pinning

- **技术要求**
- 改进我们的示例1 – 变量
- 设置基础示例
- 改进我们的基础示例
- 改进我们的示例2 – 引用
- 改进我们的示例3 – 这…不好…
- 发现自引用结构体
- 什么是move？
- Rust中的Pinning
- Pinning的理论
- 定义
- 固定到堆上
- 固定到栈上
- Pin投影与结构化Pinning
- 改进我们的示例4 – Pinning来救场
- future.rs
- http.rs
- Main.rs
- executor.rs
- **总结**

---

### 10. 创建你自己的运行时

- **技术要求**
- 设置我们的示例
- main.rs
- future.rs
- http.rs
- executor.rs
- reactor.rs
### 实验我们的运行时
- **异步Rust的挑战**
- 显式与隐式反应器实例化
- 人体工程学与效率及灵活性
- 每个人都同意的常见特性
- 异步的drop
- 异步Rust的未来
- **总结**

### 尾声

### 索引

### 你可能喜欢的其他书籍



特定章节的代码位于该章节的文件夹中（例如，ch01）。每个示例被组织为一个单独的 crate。示例名称前的字母指示了书中不同例子的展示顺序。例如，thea-runtime 示例在 b-reactor-executor 示例之前。这种方式使它们按时间顺序排列（至少在大多数系统上是默认的）。一些示例的版本后面带有 -bonus 后缀。这些版本将在书中提到，通常包含一个特定变体的示例，可能很有趣，但与当前主题并无重要关系。

下载示例代码文件
您可以从 GitHub 下载此书的示例代码文件，网址为 https://github.com/PacktPublishing/Asynchronous-Programming-in-Rust。如果代码有更新，它将在 GitHub 仓库中更新。我们还有其他代码包可供查看，来自我们丰富的图书和视频目录，网址为 https://github.com/PacktPublishing/。请查阅！

使用的约定
本书中使用了一些文本约定。

文本中的代码：指文本中的代码词、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟网址、用户输入和 Twitter 帐号。示例：“所以，现在我们创建了自己的 async 运行时，使用 Rust 的 Futures、Waker、Context 和 async/await。”

代码块的格式如下所示：

rust
复制代码

pub trait Future {
    type Output;
    fn poll(&mut self) -> PollState<Self::Output>;
}
引起您注意的代码块的特定部分，相关行或项目会加粗显示：

rust
复制代码

struct Coroutine0 {
    stack: Stack0,
    state: State0,
}
任何命令行输入或输出格式如下：

复制代码

$ cargo run
小贴士或重要说明
以这种方式出现。

联系我们
我们欢迎读者的反馈。

一般反馈：如果您对本书的任何方面有疑问，请通过电子邮件联系我们，地址是 customercare@packtpub.com，并在邮件主题中提及书名。
勘误：虽然我们已尽一切努力确保内容的准确性，但错误确实会发生。如果您在本书中发现错误，我们将非常感激您向我们报告。请访问 www.packtpub.com/support/errata 并填写表格。
盗版：如果您在互联网上发现我们作品的任何非法复制品，请向我们提供位置地址或网站名称。请通过 copyright@packt.com 联系我们，并提供材料的链接。
有意成为作者：如果您对某个主题有专业知识，并且有兴趣写作或贡献一本书，请访问 authors.packtpub.com。
分享您的想法
阅读完《Rust 中的异步编程》后，我们很想听听您的想法！请点击这里直接访问本书的 Amazon 评价页面并分享您的反馈。您的评价对我们和技术社区都很重要，将帮助我们确保提供卓越质量的内容。

下载本书的免费 PDF 副本
感谢您购买本书！您是否喜欢随身阅读，但无法随身携带纸质书籍？您的电子书购买是否与您选择的设备不兼容？别担心，现在每本 Packt 书籍都可以免费获得无 DRM 的 PDF 版本。

随处随在，在您选择的任何设备上阅读。可以直接在应用程序中搜索、复制和粘贴您喜欢的技术书籍中的代码。这些好处不止于此，您还可以独家获得每日发送至您邮箱的折扣、通讯和极好的免费内容。

获取福利的简单步骤
扫描二维码或访问以下链接。

第一部分：异步编程基础
在本部分中，您将获得对并发和异步编程的全面介绍。我们还将探索各种编程语言用于建模异步性的技术，审视其中最流行的技术，并涵盖与每种技术相关的一些优缺点。最后，我们将解释操作系统支持的事件队列的概念，如 epoll、kqueue 和 IOCP，详细说明如何使用系统调用与操作系统进行交互，并解决创建跨平台抽象（如 mio）时遇到的挑战。本节包含以下章节：

第1章：并发与异步编程：详细概述
第2章：编程语言如何建模异��程序流
第3章：理解操作系统支持的事件队列、系统调用及跨平台抽象
1. 并发与异步编程：详细概述
异步编程是许多程序员认为令人困惑的话题之一。你会觉得自己似乎理解了它，然而随后却意识到这一领域比你想象的要复杂得多。如果你参与讨论，听足够多的演讲，并在互联网上阅读关于该主题的内容，你可能也会看到一些似乎互相矛盾的说法。至少，这描述了我第一次接触这个主题时的感受。

造成这种困惑的原因往往是缺乏上下文，或者作者在没有明确说明的情况下假定了特定的上下文，同时与并发和异步编程相关的术语相对定义较差。

在本章中，我们将覆盖很多内容，并将内容分为以下主要主题：

异步历史
并发与并行
操作系统与 CPU
中断、固件和 I/O
本章的性质较为总体，并不专门关注 Rust 或任何特定的编程语言，但这是我们需要了解的背景信息，以确保大家在接下来的讨论中有相同的基础。好处是，这些知识在无论使用何种编程语言时都是有用的。在我看来，这一事实也使得本章成为本书中最有趣的章节之一。

本章中的代码不多，因此我们轻松开始。现在正是泡一杯茶、放松身心的时候，因为我们将开始这段共同的旅程。

技术要求
所有示例将用 Rust 编写，您有两种选择来运行这些示例：

在 Rust Playground 上编写和运行我们将写的示例
在您的机器上安装 Rust 并本地运行示例（推荐）
阅读本章的理想方式是克隆附带的仓库（[https://github.com/PacktPublishing/Asynchronous-Programming-in-Rust/tree/main/ch01/a-](https://github.com/PacktPublishing/Asynchronous-Programming-in-Rust/tree/main/ch01/a-））。

替代方案4 - 使用两个酒保的并行和异步任务执行
如果你雇佣两个酒保，并要求他们执行替代方案3中描述的工作，但有一个变化：允许他们互相“抢”任务，这样酒保1可以开始倒酒并将啤酒放下静置，而酒保2可以在酒保1忙于倒新订单时进行加满和服务。这样，两位酒保很少会同时忙于工作，因为正在进行的啤酒在准备好时可以及时加满和服务。几乎所有的订单都在最短的时间内完成并服务，让顾客能更快地带着啤酒离开酒吧，并为想要下新订单的顾客腾出空间。

这样，你可以进一步提高吞吐量。尽管仍无法达到理论最大值，但你会非常接近。在开业之夜，你意识到酒保们每小时处理230个订单，总吞吐量达到每小时460瓶啤酒。收入看起来不错，顾客们很高兴，成本保持在最低水平，而你则是这个世界上最奇怪酒吧（不过是个极其高效的酒吧）的一位快乐管理者。

关键要点
并发是更加明智地工作的一种方式。并行则是向问题投入更多资源的一种方式。

并发及其与 I/O 的关系
正如你从我 até 目前为止的写作中可以理解的那样，编写异步代码通常在需要聪明地充分利用你的资源时更有意义。

如果你编写一个努力解决问题的程序，通常并发就没有什么帮助。这正是并行发挥作用的地方，因为如果你能将问题拆分成可以并行处理的部分，它就为你提供了一种投放更多资源的方式。考虑下面这两种并发的不同用例：

当执行 I/O 时，你需要等待某些外部事件发生。
当你需要分散注意力，防止一个任务等待过久。
第一个是经典的 I/O 示例：你必须等待网络调用、数据库查询或其他事情发生，才能推进任务。然而，你有许多任务要做，所以与你其等着的做法是继续在其他地方工作，定期检查任务是否准备好推进，或确保你会在任务准备好时收到通知。

第二个是当有用户界面时常见的情况。假设你只有一个核心。你如何确保在执行其他密集 CPU 任务时，让整个用户界面不会变得无响应呢？你可以每16毫秒停止你正在做的任何任务，运行更新用户界面的任务，然后再恢复你之前的工作。这样，你每秒需停止并恢复任务60次，但你也会拥有一个全响应的用户界面，刷新率约为60赫兹。

操作系统提供的线程呢？
在本书后面讨论处理 I/O 的策略时，我们将更深入地讨论线程，但我在这里也会提到它们。使用操作系统线程来理解并发的一个挑战是，它们似乎被映射到核心上。尽管大多数操作系统会尽量把一个线程映射到一个核心，直到线程数量等于核心数量，但这并不一定是一个正确的思维模型。

一旦我们创建的线程数量超过核心数量，操作系统将会在我们的线程之间切换，并使用其调度程序并发处理每个线程，为每个线程提供一些运行时间。你还必须考虑到你的程序并不是唯一在系统上运行的程序。其他程序也可能会生成多个线程，这意味着线程的数量将远远超过 CPU 上的核心数。

因此，线程可以是一种并行执行任务的手段，但它们也可以是一种实现并发的手段。

正确的参考框架
关于并发的最后一部分，它需要在某种参考框架中定义。

当你编写从你的角度来看完美同步的代码时，停下来想一想，从操作系统的角度来看那是什么样子。操作系统可能根本不会从头到尾运行你的代码。它可能会多次停止和恢复你的进程。CPU 可能在你认为它只专注于你的任务时会被中断并处理一些输入。

因此，同步执行只是一个幻觉。但从你作为程序员的角度来看，它并不是，这一点非常重要：

当我们讨论并发而不提供任何其他上下文时，我们使用你作为程序员和你的代码（你的进程）作为参考框架。如果你在思考并发时没有牢记这一点，事情很快就会变得混乱。

与操作系统的通信
与操作系统的通信是通过我们称之为系统调用（syscall）的机制实现的。我们需要知道如何进行系统调用，并理解当我们想与操作系统合作和沟通时，这为何如此重要。我们还需要了解我们日常使用的基本抽象如何在后台使用系统调用。我们将在第3章进行详细讲解，所以现在先简要介绍一下。

系统调用使用操作系统提供的公共 API，这样我们在“用户空间”编写的程序就可以与操作系统通信。大多数情况下，这些调用对于我们程序员来说已被我们使用的语言或运行时抽象了。

现在，一个系统调用是一个与您正在通信的内核特有的示例，但 UNIX 系列的内核有许多相似之处。UNIX 系统通过 libc 暴露这一点。而 Windows 则使用自己的 API，通常称为 WinAPI，它的操作方式与基于 UNIX 的系统可能有很大的不同。通常，有一种方法可以实现相同的功能。在功能方面，您可能不会注意到太大的差异，但正如我们稍后看到的，尤其是当我们深入了解 epoll、kqueue 和 IOCP 的工作原理时，它们在实现这些功能的方式上可以存在很大差异。

然而，系统调用并不是我们与操作系统交互的唯一方式，接下来的部分我们将看到这一点。

CPU 与操作系统
CPU 是否与操作系统合作？如果在我第一次认为我理解程序如何工作时问我这个问题，我很可能会回答“否”。我们在 CPU 上运行程序，只要知道怎么做，就可以随心所欲。但首先，我并没有认真思考这个问题，除非你了解 CPU 和操作系统是如何协同工作的，否则很难确切知道。

让我意识到我错得很离谱的是一段类似您即将看到的代码。如果您觉得 Rust 中的内联汇编看起来陌生且令人困惑，请暂时不用担心。我们将在本书稍后进行适当的内联汇编介绍。我会逐行解释以下代码，直到您对语法更熟悉为止：

仓库参考： ch01/ac-assembly-dereference/src/main.rs

rust
复制代码

fn main() {
    let t = 100;
    let t_ptr: *const usize = &t;
    let x = dereference(t_ptr);
    println!("{}", x);
}

fn dereference(ptr: *const usize) -> usize {
    let mut res: usize;
    unsafe {
        asm!("mov {0}, [{1}]", out(reg) res, in(reg) ptr)
    };
    res
}
您看到的正是用汇编编写的间接引用函数。mov {0}, [{1}] 这行需要一些解释。{0} 和 {1} 是模板，用于告诉编译器我们正在指代 out(reg) 和 in(reg) 表示的寄存器。数字只是索引，因此如果我们有更多的输入或输出，它们将编号为 {2}、{3} 等。由于我们只指定了 reg 而不是特定寄存器，我们让编译器选择它想使用的寄存器。

mov 指令指示 CPU 从 ptr 指向的内存位置读取前 8 个字节（如果我们在 64 位计算机上），并将其放置在 {0} 所代表的寄存器中。方括号 [] 将 instruct CPU 将该寄存器中的数据视为内存地址，而不是简单地将内存地址复制到 {0}。它会提取该内存位置上的内容并移动过去。

无论如何，我们在这里只是向 CPU 编写指令。没有标准库，没有系统调用；只是原始指令。操作系统根本没有涉及到这个间接引用函数，对吧？

如果您运行这个程序，您会得到期望的结果：100。

现在，如果您保留间接引用函数，但用一个创建指向 99999999999999 地址（我们知道这个地址是无效的）的指针的函数替换 main 函数，代码变为：

rust
复制代码

fn main() {
    let t_ptr = 99999999999999 as *const usize;
    let x = dereference(t_ptr);
    println!("{}", x);
}
现在，如果我们运行它，会得到以下结果：

在 Linux 上的结果：

复制代码

Segmentation fault (core dumped)
在 Windows 上的结果：

复制代码

error: process didn't exit successfully: `target\debug\ac-assembly-dereference.exe` (exit code: 0xc0000005, STATUS_ACCESS_VIOLATION)
我们得到了段错误。这并不令人惊讶，但正如您可能注意到的那样，我们在不同平台上得到的错误是不同的。显然，操作系统以某种方式参与了这一过程。让我们看看这里实际上发生了什么。


走进兔子洞
事实证明，操作系统与 CPU 之间有着大量的合作，但这可能并不是你天真想象的那样。许多现代 CPU 提供了一些操作系统所需的基本基础设施。这些基础设施为我们提供了我们所期望的安全性和稳定性。实际上，大多数高级 CPU 提供的选项远比 Linux、BSD 和 Windows 等操作系统实际使用的要多得多。

这里我想特别提及两个方面：

CPU 如何阻止我们访问不应该访问的内存。
CPU 如何处理异步事件，例如 I/O。
我们将在这里讨论第一个问题，而第二个问题将在下一部分讨论。

CPU 如何防止我们访问不应该访问的内存？
正如我提到的，现代 CPU 架构通过设计定义了一些基本概念。以下是一些示例：

虚拟内存
页表
页故障
异常
特权等级
具体的实现方式会因具体的 CPU 而有所不同，因此我们在此将其概括性处理。

大多数现代 CPU 都配备了内存管理单元（MMU）。这一部分有时甚至与 CPU 同一块晶圆上制造。MMU 的任务是将我们在程序中使用的虚拟地址转换为物理地址。

当操作系统启动一个进程（如我们的程序）时，它会为我们的进程设置一个页表，并确保 CPU 上的一个特殊寄存器指向这个页表。

现在，当我们尝试间接引用 t_ptr 时，这个地址最终会被发送到 MMU 进行转换，MMU 会在页表中查找，并将其转换为内存中的物理地址，以便它可以提取数据。

在第一个情况下，它将指向我们栈中的一个内存地址，该地址保存着值 100。当我们输入 99999999999999 并请求提取存储在该地址的内容（这就是间接引用的功能）时，它在页表中寻找对应的翻译，却找不到。

此时，CPU 将此视为页故障。

在启动时，操作系统向 CPU 提供了一个中断描述符表。这个表具有预定义的格式，操作系统为 CPU 可能遇到的预定义条件提供处理程序。由于操作系统提供了指向处理页故障的函数的指针，当我们尝试间接引用 99999999999999 时，CPU 会跳转到该函数，从而将控制权交给操作系统。

操作系统随后会为我们打印一条友好的消息，告诉我们遇到了它所称的段错误（segmentation fault）。因此，这条消息可能会根据您运行代码的操作系统而有所不同。

我们不能直接更改 CPU 中的页表吗？
这时，特权等级就派上用场了。大多数现代操作系统采用两个环级别：环 0（内核空间）和环 3（用户空间）。

大多数 CPU 拥有比现代操作系统使用的更多环的概念
这是出于历史原因，这也是为什么使用环 0 和环 3（而不是环 1 和环 2）的原因。每个页表中的条目都有关于其额外信息。其中包含有关其所属环的信息。这些信息在您的操作系统启动时设置。

在环 0 中执行的代码几乎具有对外部设备和内存的无限制访问，可以自由更改提供硬件层面安全性的寄存器。而您在环 3 中编写的代码通常对 I/O 和某些 CPU 寄存器（以及指令）具有极其有限的访问权限。试图从环 3 中发出指令或设置寄存器以更改页表将被 CPU 阻止。CPU 会将此视为异常，并跳转到操作系统提供的该异常的处理程序。

这也是您别无选择，只能与操作系统合作并通过系统调用处理 I/O 任务的原因。如果不是这样的情况，系统将不会非常安全。

总结
简而言之：是的，CPU 和操作系统之间有很大的合作。大多数现代桌面 CPU 的设计考虑到了操作系统，因此它们提供了操作系统在启动时依附于的钩子和基础设施。当操作系统生成一个进程时，它也会设置其特权级别，确保普通进程保持在其定义的边界内，以维持稳定性和安全性。

中断、固件和 I/O
我们即将结束本书中的一般计算机科学主题，并将很快开始探索如何走出兔子洞。

这一部分试图将所有内容结合起来，观察整个计算机如何作为一个系统来处理 I/O 和并发。

让我们开始吧！

简化概述
让我们看一下我们从网络卡读取数据时的一些步骤。

中断
如您所知，存在两种类型的中断：

硬件中断
软件中断
它们在本质上是非常不同的��

硬件中断
硬件中断是通过在 IRQ 上发送电信号来产生的。这些硬件线路直接向 CPU 发出信号。

软件中断
软件中断则是由软件发出的，而不是硬件发出的。与硬件中断一样，CPU 会跳转到中断描述符表（IDT），并运行指定中断的处理程序。

固件
固件在我们大多数人眼中并没有得到太多关注；然而，它是我们生活中至关重要的一部分。固件在各种硬件上运行，并以各种奇怪且特殊的方式使我们所编程的计算机正常工作。

现在，固件需要微控制器才能工作。甚至 CPU 也有使其正常工作的固件。这意味着在我们的系统中，存在比我们编程所针对的核心更多的小“CPU”。

为什么这很重要？
好吧，您还记得并发是关于效率的，对吗？既然系统中已有许多 CPU/微控制器在为我们工作，我们写代码时的一个关注点就是不要重复或复制这些工作。

如果网络卡有固件不断检查是否有新数据到达，那么如果让我们的 CPU 也不断检查是否有新数据到达，那将非常浪费。更好的方式是偶尔检查一次，或者更好的是，当数据到达时获得通知。

总结
本章涵盖了很多内容，因此您做得很好，完成了这些基础工作。我们从历史角度了解了 CPU 和操作系统如何演变，以及非抢占式和抢占式多任务之间的区别。我们讨论了并发与并行之间的差异，谈论了操作系统的角色，并了解到系统调用是我们与宿主操作系统交互的主要方式。您还看到了 CPU 和操作系统通过设计为 CPU 一部分的基础设施进行合作的方式。

最后，我们查看了一张关于发出网络调用时会发生什么的图。您知道我们至少有三种不同的方法来处理 I/O 调用执行所需的时间，而我们必须决定以哪种方式来处理这个等待时间。

这一部分涵盖了我们所需的大部分背景信息，以确保在继续之前我们有相同的定义和概述。随着我们在书中的深入，将会有更多的详细内容，而下一章的第一个主题是编程语言如何通过线程、协程和期货模型化异步程序流程。


2. 编程语言如何模型化异步程序流
在上一章中，我们对异步程序流、并发和并行进行了概述。在本章中，我们将缩小范围。具体来说，我们将探讨编程语言和库中模型化并发的不同方式。

需要记住的是，线程、期货、纤维、协程、承诺等都是抽象，它们为我们提供了一种模型化异步程序流的方式。它们各有优缺点，但共同的目标是为程序员提供一种易于使用（同样重要的是，不容易误用）、高效且富有表现力的方式，以创建以非顺序且往往不可预测的方式处理任务的程序。

在这里，缺乏准确的定义同样普遍；许多术语的名称源于某个特定时间的具体实现，但后来被赋予了更普遍的意义，涵盖了同一事物的不同实现和变种。

我们将首先通过它们的相似性来对不同的抽象进行分组，然后再讨论每种抽象的优缺点。我们还会介绍一些将在全书中使用的重要定义，并详细讨论操作系统线程。

我们讨论的主题相对抽象且复杂，所以如果您不能立即理解所有内容，也不要感到沮丧。随着我们在书中的深入，通过处理一些示例，您会逐渐习惯不同的术语和技术，更多的知识会变得清晰。

具体而言，将涵盖以下主题：

定义
操作系统提供的线程
绿色线程/栈满协程/纤维
基于回调的方法
承诺、期货以及 async/await
定义
我们可以将并发操作的抽象大致分为两类：

协作式：这些任务自愿让出控制权，要么通过明确的让步，要么通过调用一个在另一项操作完成之前无法进一步推进时挂起任务的函数（例如发起网络调用）。这些任务通常会让出控制权给某种调度程序。Rust 和 JavaScript 中的 async/await 生成的任务就是这类任务的例子。

非协作式：这些任务不一定自愿让出控制权。在这样的系统中，调度程序必须能够抢先控制正在运行的任务，这意味着调度程序可以停止任务并控制 CPU，即使该任务能够继续工作并推进。操作系统线程和 Goroutines（自 Go 版本 1.14 之后）就是这类任务的例子。

嵌入式系统
嵌入式系统如今比以往任何时候都更为普遍。这种硬件可能没有足够的资源运行操作系统，如果有，它们可能会使用一种与您的需求高度契合的根本不同的操作系统，因为这些系统往往不那么通用，而具有更专门化的特点。

它们对线程的支持和调度特性可能与您在像 Windows 或 Linux 这样的操作系统中所习惯的不同。由于涵盖所有不同设计将是一本独立的书籍，我们将局限于讨论在流行的桌面和服务器 CPU 上运行的 Windows 和 Linux 系统中的线程。

操作系统线程很容易实现和使用。我们只需让操作系统为我们处理所有事务。我们通过为每个要完成的任务生成一个新的操作系统线程，并像平常一样编写代码来实现这一点。我们处理并发的运行时环境就是操作系统本身。除了这些优点之外，您还可以免费获得并行性。然而，直接管理并行性和共享资源也会带来一些缺点和复杂性。

创建新线程所需时间
创建一个新的操作系统线程涉及一些记录和初始化开销，因此虽然在相同进程中切换两个现有线程相当快速，但创建新线程和丢弃不再使用的线程会涉及耗时的工作。如果系统需要创建和丢弃大量线程，这一额外的工作将限制吞吐量。如果有大量的小任务需要并发处理，这在处理大量 I/O 时往往是个问题。

每个线程都有自己的栈
我们将在本书后面详细介绍栈，但现在知道它们占据固定大小的内存就足够了。每个操作系统线程都有自己独立的栈，即使许多系统允许配置这个大小，它们仍然是固定的，无法增长或缩小。毕竟，栈溢出就是由此造成的，如果您将其配置得过小而无法满足正在运行的任务，就会成为一个问题。

如果我们有许多只需要少量栈空间的小任务，但我们预留了比所需更多的栈空间，那么我们将占用大量内存，并可能耗尽可用内存。

上下文切换
正如您现在所知道的，线程和调度程序是紧密相连的。上下文切换发生在 CPU 停止执行一个线程并转到另一个线程时。尽管这个过程经过高度优化，但它仍涉及到存储和恢复寄存器状态，这需要时间。每次您让出控制权给操作系统调度程序时，它可以选择在该 CPU 上调度一个来自不同进程的线程。

您看到，这些系统创建的线程属于一个进程。当您启动一个程序时，它启动一个进程，该进程创建至少一个初始线程，并在该线程中执行您编写的程序。每个进程可以生成多个共享同一地址空间的线程。这意味着在同一进程内的线程可以访问共享内存，并可以访问相同的资源，例如文件和文件句柄。

这样的结果是，当操作系统通过停止一个线程并恢复同一进程中的另一个线程来进行上下文切换时，它不需要保存和恢复与该进程相关的所有状态，仅需保存与该线程相关的状态。

另一方面，当操作系统从与一个进程相关的线程切换到与另一个进程相关的线程时，新进程将使用不同的地址空间，操作系统需要采取措施确保进程“A”不会访问属于进程“B”的数据或资源。如果不这样做，系统的安全性将受到威胁。

因此，结果是可能需要冲刷缓存，并且可能需要保存和恢复更多的状态。在高并发的系统中，当负载增加时，这些上下文切换可能会额外耗时，从而在频繁发生时以某种不可预测的方式限制吞吐量。

调度
操作系统可以以您可能不期望的方式调度任务，每当您让位于操作系统时，您就会与系统上所有其他线程和进程排在同一个队列中。

此外，由于没有保证线程会在与其离开时相同的 CPU 核心上恢复执行，或者两个任务不会并行运行并尝试访问相同的数据，因此您需要同步数据访问，以防止数据竞争和与多核编程相关的其他陷阱。

作为一门语言，Rust 将帮助您防止许多这些陷阱，但同步数据访问将需要额外的工作，并增加此类程序的复杂性。我们常常说，使用操作系统线程来处理并发为我们免费提供了并行性，但在增加复杂性和对正确数据访问同步的需求方面，这并不是免费的。



线程与调度器的关系
如您现在所知，线程和调度器是紧密相连的。上下文切换发生在 CPU 停止执行一个线程并转向另一个线程时。尽管这个过程经过高���优化，但它仍涉及到存储和恢复寄存器状态，这需要时间。每当您将控制权让给操作系统调度程序时，它可以选择在该 CPU 上调度不同进程中的一个线程。

您会看到，这些系统创建的线程属于一个进程。当您启动一个程序时，它会启动一个进程，该进程创建至少一个初始线程，并在该线程中执行您编写的程序。每个进程可以生成多个共享同一地址空间的线程。

这意味着，同一进程内的线程可以访问共享内存，并可以访问相同的资源，例如文件和文件句柄。这样做的一个后果是，当操作系统通过停止一个线程并恢复同一进程中的另一个线程来进行上下文切换时，它不需要保存和恢复与该进程相关的所有状态，只需保存与该线程相关的状态。

另一方面，当操作系统从一个进程相关的线程切换到另一个进程相关的线程时，新进程将使用不同的地址空间，操作系统需要采取措施确保进程“A”不会访问属于进程“B”的数据或资源。如果不这样做，系统将是不安全的。

因此，缓存可能需要被清空，并且可能需要保存和恢复更多的状态。在高并发的系统负载下，这些上下文切换可能会额外耗时，从而在频繁发生时以某种不可预测的方式限制吞吐量。

调度
操作系统可以以您可能不期望的方式调度任务，每当您向操作系统让出控制权时，您会与系统上所有其他线程和进程排在同一个队列中。

此外，由于没有保证线程会在与其离开时相同的 CPU 核心上恢复执行，或者两个任务不会同时运行并尝试访问相同的数据，您需要同步数据访问，以防止数据竞争和与多核编程相关的其他陷阱。

作为一门语言，Rust 将帮助您防止许多这些陷阱，但同步数据访问将需要额外的工作，并增加此类程序的复杂性。我们常常说，使用操作系统线程来处理并发为我们提供了免费的并行性，但在增加复杂性和对正确数据访问同步的需求方面，这并不是免费的。

将异步操作与操作系统线程解耦的优势
将异步操作与线程的概念解耦有很多好处。首先，使用操作系统线程来处理并发要求我们使用本质上是操作系统抽象的手段来表示我们的任务。

拥有一个单独的抽象层来表示并发任务让我们自由选择如何处理并发操作。如果我们在 Rust 中创建一个用于并发操作的抽象，比如期货（future）、在 JavaScript 中的承诺（promise）或 Go 中的协程（goroutine），那么由运行时的实现者决定如何处理这些并发任务。

运行时可以简单地将每个并发操作映射到一个操作系统线程，或者使用纤维/绿色线程或状态机来表示任务。编写异步代码的程序员如果底层实现发生变化可能不需要对其代码进行任何更改。

理论上，相同的异步代码可以在没有操作系统的微控制器上用来处理并发操作，只要有相应的运行时即可。

总结
使用操作系统提供的线程来处理并发具有以下优势：

易于理解
易于使用
任务之间的切换相对快速
免费获得并行性
然而，它们也有一些缺点。
将异步操作与线程的概念解耦具有许多好处。首先，使用操作系统线程来处理并发要求我们使用本质上是操作系统抽象的手段来表示我们的任务。

拥有一个单独的抽象层来表示并发任务让我们自由选择如何处理并发操作。如果我们创建一个并发操作的抽象，例如 Rust 中的期货（future）、JavaScript 中的承诺（promise）或 Go 中的协程（goroutine），那么如何处理这些并发任务的决定将取决于运行时的实现者。

运行时可以简单地将每个并发操作映射到一个操作系统线程，也可以使用纤维/绿色线程或状态机来表示任务。编写异步代码的程序员在底层实现发生变更时不一定需要对其代码进行任何修改。

理论上，相同的异步代码可以在没有操作系统的微控制器上用于处理并发操作，只要有适用的运行时即可。

总结
使用操作系统提供的线程来处理并发具有以下优势：

容易理解
易于使用
任务之间的切换相对快速
免费获得并行性
然而，它们也有一些缺点：

操作系统级线程通常具有较大的栈。如果有许多任务同时等待（例如在负载很重的网络服务器中），您会很快耗尽内存。
上下文切换可能会很昂贵，并且由于将所有调度都交给操作系统，您可能会获得不可预测的性能。操作系统需要处理的事务非常多，可能无法像您希望的那样快速切换回您的线程。
它与操作系统抽象紧密耦合。在某些系统上，这可能不是一个可选项。
示例
由于在本书中我们不会花更多时间讨论操作系统线程，因此我们将通过一个简短的示例来展示它们是如何使用的。



ch02/aa-os-threads use std::thread::{self, sleep}; fn main() {     println!("So, we start the program here!");     let t1 = thread::spawn(move || {         sleep(std::time::Duration::from_millis(200));         println!("The long running tasks finish last!");     }); 
    let t2 = thread::spawn(move || {         sleep(std::time::Duration::from_millis(100));         println!("We can chain callbacks...");         let t3 = thread::spawn(move || {             sleep(std::time::Duration::from_millis(50));             println!("...like this!");         });         t3.join().unwrap();     });     println!("The tasks run concurrently!");     t1.join().unwrap();     t2.join().unwrap(); }

在这个示例中，我们简单地启动了几个操作系统线程，并将它们置于休眠状态。休眠本质上与向操作系统调度程序让出控制权的请求相同，希望在经过一段时间后重新调度运行。为了确保我们的主线程不会在子线程有时间运行之前完成并退出（这将导致进程退出），我们在主函数末尾将它们连接（join）在一起。如果我们运行这个示例，就会看到操作的顺序会根据我们将每个线程让给调度程序的时间长短而发生变化：

所以，我们在这里启动程序！
任务并发运行！
我们可以链式回调...
...像这样！
长时间运行的任务最后完成！
因此，尽管使用操作系统线程对许多任务来说非常有效，但我们也概述了一些思考替代方案的良好理由，讨论了它们的局限性和缺点。我们将要讨论的第一个替代方案是我们所称的纤维和绿色线程。

纤维和绿色线程
注意！ 这是一个 M:N 线程的示例，许多任务可以在一个操作系统线程上并发运行。纤维和绿色线程通常被称为“栈满协程”。

“绿色线程”这个名称最初源自 Java 中早期实现的 M:N 线程模型，后来与不同的 M:N 线程实现相关联。您会遇到这个术语的不同变体，例如 Erlang 中使用的“绿色进程”，它们与我们在这里讨论的有所不同。您还会看到一些将绿色线程的定义比我们在此处提供的更为广泛。

在本书中，我们将绿色线程定义为与纤维同义，因此在后续中这两个术语都指代相同的概念。

纤维和绿色线程的实现意味着存在一个运行时和一个负责调度哪个任务（M）在操作系统线程（N）上运行的调度程序。任务的数量远远超过操作系统线程的数量，这样的系统可以只使用一个操作系统线程正常运行。后者的情况通常被称为 M:1 线程。

Goroutines 是栈满协程的一种特定实现，但它有些细微的差别。“协程”这个术语通常暗示它们是协作性的，但 Goroutines 可以被调度程序抢占（至少自版本 1.14 以来），因此在我们在这里提出的类别中，它们处于某种灰色地带。

绿色线程和纤维使用与操作系统相同的机制，为每个任务设置一个栈，保存 CPU 的状态，并通过执行上下文切换从一个任务（线程）跳转到另一个。我们将控制权让给调度程序（这在这样的系统中是运行时的核心部分），然后调度程序继续运行另一个任务。

执行状态存储在每个栈中，因此在这样的解决方案中，不需要 async、await、Future 或 Pin。在许多方面，绿色线程模仿了操作系统如何促进并发，实施它们是一个很好的学习经验。

使用纤维/绿色线程处理并发任务的运行时可以具有很高的灵活性。任务可以在任何时间和执行的任何点被抢占和上下文切换，因此，一个占用 CPU 的长时间运行任务理论上可以被运行时抢占，从而避免由于边缘情况或程序员错误而导致任务阻塞整个系统。

这使得运行时调度程序几乎具备与操作系统调度程序相同的能力，这是使用纤维/绿色线程系统的最大优势之一。

典型流程如下：
您运行一些非阻塞代码。
您对某个外部资源进行阻塞调用。
CPU 跳转到主线程，调度一个不同的线程运行，并跳转到该线程的栈。
您在新线程上运行一些非阻塞代码，直到进行新的阻塞调用或任务完成。
CPU 再次跳转回主线程，调度一个准备好继续执行的新线程，并跳转到该线程。

每个栈都有一个固定的空间

由于纤程（fibers）和绿色线程（green threads）与操作系统线程（OS threads）相似，它们也存在一些相同的缺点。每个任务都被分配了一个固定大小的栈，因此你仍然需要预留比实际使用更多的空间。然而，这些栈可以是可增长的，这意味着一旦栈满了，运行时可以扩展栈的大小。虽然这听起来很简单，但实际上这是一个相当复杂的问题。

我们不能像树一样简单地扩展栈。实际上，需要发生以下两种情况之一：

你分配一个新的连续内存块，并处理栈分布在两个不连续内存段中的情况。
你分配一个更大的新栈（例如，是之前栈大小的两倍），将所有数据移动到新栈中，然后继续执行。
第一种解决方案听起来很简单，因为你可以保留原始栈不变，基本上可以在需要时切换到新栈并继续执行。然而，现代CPU如果能够在一个连续的内存块上工作，由于缓存和它们预测下一条指令将要处理的数据的能力，可以非常快速地工作。将栈分布在两个不连续的内存块中会降低性能。当你有一个循环恰好位于栈边界时，这种情况尤其明显，因此你最终可能会为每次循环迭代进行多达两次的上下文切换。

第二种解决方案通过使栈成为一个连续的内存块来解决第一种解决方案的问题，但它也带来了一些问题。首先，你需要分配一个新栈并将所有数据移动到新栈中。但是，当所有内容都移动到新位置时，指向栈上内容的指针和引用会发生什么？你猜对了：每个指向栈上内容的指针和引用都需要更新，以指向新位置。这既复杂又耗时，但如果你的运行时已经包含垃圾回收器，你已经有了跟踪所有指针和引用的开销，所以这可能比非垃圾回收程序的问题要小。然而，每次栈增长时，都需要垃圾回收器和运行时之间进行大量的集成，因此实现这种运行时可能会变得非常复杂。

其次，你必须考虑如果你有很多长时间运行的任务，这些任务在短时间内需要大量栈空间（例如，如果任务开始时涉及大量递归），但在其余时间主要是I/O绑定的情况。你最终会多次扩展栈，只是为了任务的一个特定部分，并且你必须决定是否接受任务占用比实际需要更多的空间，或者在某个时候将其移回较小的栈。这对你的程序的影响当然会根据你所做的工作类型而有很大差异，但这仍然是你需要注意的事情。

上下文切换

尽管这些纤程/绿色线程与操作系统线程相比是轻量级的，但你仍然需要在每次上下文切换时保存和恢复寄存器。这在大多数情况下可能不会成为问题，但与不需要上下文切换的替代方案相比，它可能会效率较低。上下文切换也可能非常复杂，特别是如果你打算支持许多不同的平台。
调度
当一个纤程（fiber）或绿色线程（green thread）让出控制权给运行时调度器时，调度器可以简单地恢复执行一个新的、已经准备好运行的任务。这意味着你避免了每次让出控制权给调度器时被放入与系统中所有其他任务相同的运行队列的问题。从操作系统的角度来看，你的线程一直在忙于工作，因此操作系统会尽量避免抢占它们。

这种方法的一个意想不到的缺点是，大多数操作系统调度器通过为每个操作系统线程分配一个时间片来确保所有线程都能获得一些运行时间，在这个时间片内，线程可以运行，直到操作系统抢占该线程并在该CPU上调度一个新线程。使用多个操作系统线程的程序可能会被分配更多的时间片，而使用较少操作系统线程的程序则可能被分配较少的时间片。使用M:N线程模型的程序很可能只使用少数几个操作系统线程（在大多数系统上，每个CPU核心一个线程似乎是起点）。因此，根据系统上运行的其他程序，你的程序可能会被分配比使用多个操作系统线程时更少的时间片。然而，考虑到现代CPU上可用的核心数量以及并发系统上的典型工作负载，这种影响应该是最小的。

FFI（外部函数接口）
由于你创建了自己的栈，这些栈在某些条件下可能会增长或缩小，并且可能有一个调度器假设它可以在任何时候抢占正在运行的任务，因此在使用FFI时，你必须采取额外的措施。大多数FFI函数都假设使用操作系统提供的普通C栈，因此从纤程或绿色线程调用FFI函数很可能会出现问题。你需要通知运行时调度器，切换到不同的操作系统线程，并以某种方式通知调度器你已经完成，纤程或绿色线程可以继续执行。这自然会给运行时实现者和进行FFI调用的用户带来额外的开销和复杂性。

优点
对用户来说使用简单。代码看起来与使用操作系统线程时一样。
上下文切换速度相对较快。
与操作系统线程相比，内存使用量较大时问题较小。
你可以完全控制任务的调度方式，并且可以根据需要优先处理它们。
很容易引入抢占机制，这是一个强大的功能。
缺点
当栈空间不足时，栈需要一种增长的方式，这会增加额外的工作和复杂性。
你仍然需要在每次上下文切换时保存CPU状态。
如果你打算支持多个平台和/或CPU架构，正确实现起来会非常复杂。
FFI可能会带来大量开销，并增加意外的复杂性。
基于回调的方法
注意！
这是M:N线程模型的另一个例子。许多任务可以在一个操作系统线程上并发运行。每个任务由一系列回调组成。你可能已经从JavaScript中了解了我们接下来要讨论的内容，我假设大多数人都知道这一点。

基于回调的方法
基于回调的方法的核心思想是保存一组我们稍后想要运行的指令的指针，以及所需的任何状态。在Rust中，这通常是一个闭包（closure）。

在大多数语言中，实现回调相对容易。它们不需要任何上下文切换，也不需要为每个任务预分配内存。

然而，使用回调来表示并发操作要求你从一开始就以完全不同的方式编写程序。将一个使用正常顺序程序流的程序重写为使用回调的程序，需要进行大量的重写工作，反之亦然。

基于回调的并发可能难以推理，并且可能变得非常复杂。大多数JavaScript开发者都熟悉的“回调地狱”这一术语并非偶然。

由于每个子任务必须保存它稍后所需的所有状态，内存使用量将随着任务中回调数量的增加而线性增长。

优点
在大多数语言中易于实现。
不需要上下文切换。
内存开销相对较低（在大多数情况下）。
缺点
内存使用量随着回调数量的增加而线性增长。
程序和代码可能难以推理。
这是一种非常不同的编程方式，它将影响程序的几乎所有方面，因为所有让出操作都需要一个回调。
所有权可能难以推理。因此，在没有垃圾回收器的情况下编写基于回调的程序可能会变得非常困难。
由于所有权规则的复杂性，任务之间共享状态很困难。
调试回调可能很困难。
协程：Promise 和 Future
注意！
这是M:N线程模型的另一个例子。许多任务可以在一个操作系统线程上并发运行。每个任务表示为一个状态机。

JavaScript中的Promise和Rust中的Future是基于相同思想的两种不同实现。

通过这种方式，我们可以编写处理并发操作的程序，几乎就像编写普通的顺序程序一样。

我们的JavaScript程序现在可以写成如下形式：

async function run() {
    await timer(200);
    await timer(100);
    await timer(50);
    console.log("I'm the last one");
}
你可以将run函数视为一个由多个子任务组成的可暂停任务。在每个await点，它将控制权让给调度器（在这种情况下，它是著名的JavaScript事件循环）。一旦其中一个子任务的状态变为fulfilled或rejected，任务就会被调度继续执行下一步。

在使用Rust时，你可以看到类似的转换发生在函数签名中，当你编写如下代码时：

async fn run() -> () { … }
该函数包装了返回对象，并且不是返回类型()，而是返回一个输出类型为()的Future：

Fn run() -> impl Future<Output = ()>
从语法上看，Rust的futures 0.1与我们刚刚展示的promise示例非常相似，而我们现在使用的Rust futures与JavaScript中的async/await工作机制有很多共同之处。

这种将看似普通的函数和代码重写为其他形式的方式有很多好处，但也不是没有缺点。

与任何无栈协程实现一样，完全抢占可能难以实现，甚至不可能实现。这些函数必须在特定点让出控制权，与纤程/绿色线程不同，无法在栈帧中间暂停执行。通过在运行时或编译器在每个函数调用处插入抢占点，可以实现某种程度的抢占，但这与能够在任务执行的任何点抢占任务并不相同。

抢占点
抢占点可以被视为插入代码，调用调度器并询问它是否希望抢占任务。这些点可以由编译器或你使用的库在每个新函数调用之前插入。

此外，你需要编译器支持才能充分利用它。具有元编程能力（如宏）的语言可以模拟许多相同的功能，但这仍然不如编译器意识到这些特殊的异步任务时那样无缝。

调试是另一个在实现futures/promises时需要特别注意的领域。由于代码被重写为状态机（或生成器），你将无法获得与普通函数相同的堆栈跟踪。通常，你可以假设函数的调用者在堆栈和程序流中都位于它之前。对于futures和promises，可能是运行时调用了推进状态机的函数，因此可能没有一个好的回溯可以用来查看在调用失败函数之前发生了什么。有一些方法可以解决这个问题，但大多数方法都会带来一些开销。

优点
你可以像平常一样编写代码和建模程序。
不需要上下文切换。
可以以非常高效的内存方式实现。
易于在各种平台上实现。
缺点
完全实现抢占可能很困难，甚至不可能，因为任务无法在栈帧中间停止。
需要编译器支持才能充分利用其优势。
由于非顺序的程序流以及从回溯中获得的信息有限，调试可能会很困难。
总结
你还在这里？太棒了！恭喜你完成了所有这些背景信息的学习。我知道阅读描述抽象和代码的文本可能会让人望而生畏，但我希望你现在明白为什么在书的开头就讨论这些高级主题对我们来说如此有价值。我们很快就会进入示例部分。我保证！

在本章中，我们讨论了如何通过使用操作系统提供的线程以及编程语言或库提供的抽象来建模和处理编程语言中的异步操作。虽然这不是一个详尽的列表，但我们讨论了一些最流行和广泛使用的技术，并讨论了它们的优点和缺点。

我们花了相当多的时间深入探讨了线程、协程、纤程、绿色线程和回调，因此你应该对它们是什么以及它们之间的区别有了很好的了解。


下一章将详细介绍我们如何进行系统调用并创建跨平台抽象，以及像Epoll、Kqueue和IOCP这样的操作系统支持的事件队列到底是什么，为什么它们是你在大多数异步运行时中会遇到的基础。


# 第三章 Understanding OS-Backed Event Queues, SystemCalls, and Cross-Platform Abstractions 理解操作系统支持的事件队列、系统调用和跨平台抽象

在本章中，我们将探讨操作系统支持的事件队列是如何工作的，以及三种不同的操作系统如何以不同的方式处理这一任务。之所以要深入探讨这一点，是因为我所知的大多数异步运行时都使用这种操作系统支持的事件队列作为实现高性能 I/O 的基础部分。在阅读有关异步代码如何真正工作的内容时，你很可能会经常听到对这些内容的引用。

基于我们在本章讨论的技术的事件队列被用于许多流行的库中，例如：

mio（https://github.com/tokio-rs/mio），这是 Tokio 等流行运行时的关键部分。
polling（https://github.com/smol-rs/polling），这是 Smol 和 async-std 中使用的事件队列。
libuv（https://libuv.org/），这是用于创建 Node.js（一个 JavaScript 运行时）和 Julia 编程语言中使用的事件队列的库。
C# 用于其异步网络调用。
Boost.Asio，这是一个用于 C++ 的异步网络 I/O 库。
我们与主机操作系统的所有交互都是通过系统调用（syscalls）完成的。要在 Rust 中进行系统调用，我们需要知道如何使用 Rust 的外部函数接口（FFI）。

除了了解如何使用 FFI 和进行系统调用外，我们还需要讨论跨平台抽象。在创建事件队列时，无论是自己创建还是使用库，你都会注意到，如果你只对例如 Windows 上的 IOCP 如何工作有一个高层次的了解，这些抽象可能会显得有点不直观。这是因为这些抽象需要提供一个 API，涵盖不同操作系统以不同方式处理相同任务的事实。这个过程通常涉及识别平台之间的共同点，并在此基础上构建一个新的抽象。

为了解释 FFI、系统调用和跨平台抽象，我们将通过一个简单的例子来逐步引入这个话题，而不是使用一个复杂且冗长的例子。当我们稍后遇到这些概念时，我们已经对这些主题有了足够的了解，因此我们可以为后续章节中更有趣的例子做好充分准备。

在本章中，我们将讨论以下主要主题：

为什么要使用操作系统支持的事件队列？
基于就绪状态的事件队列
基于完成的事件队列
epoll
kqueue
IOCP
系统调用、FFI 和跨平台抽象
注意：虽然我们在这里没有涵盖，但你应该了解一些流行的、尽管较少使用的替代方案：

wepoll：它在 Windows 上使用特定的 API 并封装了 IOCP，因此它非常类似于 Linux 上的 epoll，而不是常规的 IOCP。这使得在两个不同的技术上创建一个具有相同 API 的抽象层变得更加容易。它被 libuv 和 mio 使用。
io_uring：这是 Linux 上一个相对较新的 API，与 Windows 上的 IOCP 有许多相似之处。
我相信，在你阅读完接下来的两章后，如果你想要了解更多关于这些内容的信息，你会很容易地阅读这些内容。

技术要求：本章不需要你设置任何新的内容，但由于我们正在为三个不同的平台编写一些低级代码，因此如果你想要运行所有示例，你需要访问这些平台。最好的方法是打开你计算机上的配套仓库并导航到 ch03 文件夹。

本章有点特别，因为我们从基础开始构建一些基本的理解，这意味着其中一些内容相当低级，并且需要特定的操作系统和 CPU 系列才能运行。别担心；我选择了最常用和流行的 CPU，所以这应该不是问题，但这是你需要意识到的事情。

机器必须在 Windows 和 Linux 上使用使用 x86-64 指令集的 CPU。Intel 和 AMD 的桌面 CPU 使用这种架构，但如果你在 ARM 处理器上运行 Linux（或 WSL），你可能会遇到一些使用内联汇编的示例的问题。在 macOS 上，书中的示例针对较新的 M 系列芯片，但仓库中也包含针对较旧的基于 Intel 的 Mac 的示例。

不幸的是，一些针对特定平台的示例需要该特定操作系统才能运行。然而，这将是唯一一章你需要访问三个不同平台才能运行所有示例的章节。接下来，我们将创建可以在所有平台上本地运行或使用 Windows Subsystem for Linux（WSL）运行的示例，但为了理解跨平台抽象的基础知识，我们实际上需要创建针对这些不同平台的示例。

行 Linux 示例
如果你没有设置 Linux 机器，你可以在 Rust Playground 上运行 Linux 示例，或者如果你使用的是 Windows 系统，我建议你设置 WSL 并在那里运行代码。你可以在 https://learn.microsoft.com/en-us/windows/wsl/install 找到如何设置 WSL 的说明。
记住，你还需要在 WSL 环境中安装 Rust，因此请按照本书前言部分关于如何在 Linux 上安装 Rust 的说明进行操作。
如果你使用 VS Code 作为编辑器，有一种非常简单的方法可以将你的环境切换到 WSL。按下 Ctrl+Shift+P，然后输入 Reopen folder in WSL。这样，你可以轻松地在 WSL 中打开示例文件夹，并在 Linux 环境中运行代码示例。

为什么要使用操作系统支持的事件队列？
你现在已经知道，我们需要与操作系统紧密合作，以使 I/O 操作尽可能高效。Linux、macOS 和 Windows 等操作系统提供了多种执行 I/O 的方式，包括阻塞和非阻塞。
I/O 操作需要通过操作系统进行，因为它们依赖于操作系统抽象的资源。这可能是磁盘驱动器、网卡或其他外围设备。特别是在网络调用的情况下，我们不仅依赖于自己的硬件，还依赖于可能远离我们自己的资源，这会导致显著的延迟。
在上一章中，我们讨论了编程时处理异步操作的不同方法，虽然它们各不相同，但它们都有一个共同点：在进行系统调用时，它们需要控制何时以及是否应该让出给操作系统调度程序。
实际上，这意味着需要避免通常会让出给操作系统调度程序的系统调用（阻塞调用），而需要使用非阻塞调用。我们还需要一种高效的方式来了解每个调用的状态，以便我们知道何时可以继续执行原本会阻塞的任务。这就是在异步运行时中使用操作系统支持的事件队列的主要原因。
我们将以三种不同的方式处理 I/O 操作为例进行探讨。

阻塞 I/O
当我们要求操作系统执行阻塞操作时，它将挂起发出调用的操作系统线程。然后，它会存储我们在发出调用时的 CPU 状态，并继续执行其他任务。当通过网络接收到数据时，它会再次唤醒我们的线程，恢复 CPU 状态，并让我们继续执行，就像什么都没发生过一样。
对于程序员来说，阻塞操作是最不灵活的，因为我们在每次调用时都会将控制权让给操作系统。最大的优势是，一旦我们等待的事件准备就绪，我们的线程就会被唤醒，从而可以继续执行。如果我们考虑到整个系统在操作系统上运行的情况，这是一个相当高效的解决方案，因为操作系统会为有工作要做的线程分配 CPU 时间以推进任务。然而，如果我们缩小范围，单独查看我们的进程，我们会发现每次进行阻塞调用时，我们都会让一个线程进入睡眠状态，即使我们的进程仍有工作可以做。这让我们面临选择：要么生成新线程来执行工作，要么接受我们必须等待阻塞调用返回。我们稍后会对此进行更详细的讨论。

非阻塞 I/O
与阻塞 I/O 操作不同，操作系统不会挂起发出 I/O 请求的线程，而是给它一个句柄，线程可以使用该句柄询问操作系统事件是否准备就绪。我们称查询状态的过程为轮询（polling）。
非阻塞 I/O 操作为我们程序员提供了更多的自由，但通常这也伴随着责任。如果我们轮询得太频繁，比如在一个循环中，我们将占用大量的 CPU 时间只是为了询问更新状态，这是非常浪费的。如果我们轮询得太少，事件准备就绪和我们采取行动之间会有显著的延迟，从而限制我们的吞吐量。

通过 epoll/kqueue 和 IOCP 进行事件队列
这是前两种方法的混合体。在网络调用的情况下，调用本身是非阻塞的。然而，我们不需要定期轮询句柄，而是可以将该句柄添加到事件队列中，并且我们可以以极小的开销处理数千个句柄。
作为程序员，我们现在有了一个新的选择。我们可以定期查询队列以检查我们添加的事件是否改变了状态，或者我们可以对队列进行阻塞调用，告诉操作系统我们希望当队列中至少有一个事件改变状态时被唤醒，以便等待该特定事件的任务可以继续执行。
这使我们能够在没有更多工作要做且所有任务都在等待事件发生时才将控制权让给操作系统。我们可以自己决定何时发出这样的阻塞调用。

注意：我们不会涵盖诸如 poll 和 select 之类的方法。大多数操作系统都有一些较旧的方法，这些方法在现代异步运行时中并不广泛使用。只需知道，我们还可以进行其他调用，这些调用本质上试图提供与我们刚刚讨论的事件队列相同的灵活性。

基于就绪状态的事件队列
epoll 和 kqueue 被称为基于就绪状态的事件队列，这意味着它们会在某个操作准备好执行时通知你。一个典型的例子是当一个套接字准备好被读取时。
为了了解这在实践中是如何工作的，我们可以看看使用 epoll 或 kqueue 从套接字读取数据时会发生什么：

我们通过调用系统调用 epoll_create 或 kqueue 创建一个事件队列。
我们向操作系统请求一个表示网络套接字的文件描述符。
通过另一个系统调用，我们注册对该套接字的读取事件（Read events）的兴趣。重要的是，我们还需要通知操作系统，当事件在我们第一步创建的事件队列中准备就绪时，我们希望收到通知。
接下来，我们调用 epoll_wait 或 kevent 来等待事件。这将阻塞（挂起）调用它的线程。
当事件准备就绪时，我们的线程被解除阻塞（恢复），并从等待调用中返回，同时返回有关发生事件的数据。
我们对第二步中创建的套接字调用 read。

图 3.1 – epoll 和 kqueue 流程的简化视图
基于完成状态的事件队列
IOCP 是输入/输出完成端口（Input/Output Completion Port）的缩写。这是一种基于完成状态的事件队列。这种类型的队列会在事件完成时通知你。一个典型的例子是当数据被读取到缓冲区时。
以下是这种事件队列的基本流程：

我们通过调用系统调用 CreateIoCompletionPort 创建一个事件队列。
我们创建一个缓冲区，并向操作系统请求一个套接字的句柄。
我们通过另一个系统调用注册对该套接字的读取事件（Read events）的兴趣，但这次我们还传递了在第二步中创建的缓冲区，数据将被读取到这个缓冲区中。
接下来，我们调用 GetQueuedCompletionStatusEx，它将阻塞，直到某个事件完成。
我们的线程被解除阻塞，缓冲区现在填充了我们感兴趣的数据。

IOCP 是输入/输出完成端口（Input/Output Completion Port）的缩写。 这是一种基于完成状态的事件队列。这种类型的队列会在事件完成时通知你。一个典型的例子是当数据被读取到缓冲区时。
以下是这种事件队列的基本流程：

我们通过调用系统调用 CreateIoCompletionPort 创建一个事件队列。
我们创建一个缓冲区，并向操作系统请求一个套接字的句柄。
我们通过另一个系统调用注册对该套接字的读取事件（Read events）的兴趣，但这次我们还传递了在第二步中创建的缓冲区，数据将被读取到这个缓冲区中。
接下来，我们调用 GetQueuedCompletionStatusEx，它将阻塞，直到某个事件完成。
我们的线程被解除阻塞，缓冲区现在填充了我们感兴趣的数据。
图 3.2 – IOCP 流程的简化视图

epoll、kqueue 和 IOCP
epoll 是 Linux 实现事件队列的方式。在功能上，它与 kqueue 有很多共同点。在 Linux 上使用 epoll 相对于其他类似方法（如 select 或 poll）的优势在于，epoll 被设计为能够非常高效地处理大量事件。

kqueue 是 macOS 实现事件队列的方式（起源于 BSD），在 FreeBSD 和 OpenBSD 等操作系统中也有使用。从高层次的功能来看，它在概念上与 epoll 相似，但在实际使用中有所不同。

IOCP 是 Windows 处理这种事件队列的方式。在 Windows 中，完成端口会在事件完成时通知你。这听起来可能像是一个微小的区别，但实际上并非如此。这在编写库时尤为明显，因为抽象化这两种方式意味着你必须将 IOCP 建模为基于就绪状态（readiness-based）或将 epoll/kqueue 建模为基于完成状态（completion-based）。向操作系统借出缓冲区也带来了一些挑战，因为在等待操作返回时，保持缓冲区不被修改非常重要。

平台	事件队列类型
Windows	IOCP
Linux	epoll
macOS	kqueue
类型	基于完成状态
表 3.1 – 不同平台和事件队列

跨平台事件队列
在创建跨平台事件队列时，你必须处理这样一个事实：你需要创建一个统一的 API，无论它是用于 Windows（IOCP）、macOS（kqueue）还是 Linux（epoll）。最明显的区别是，IOCP 是基于完成状态的，而 kqueue 和 epoll 是基于就绪状态的。

这种根本性的区别意味着你必须做出选择：

你可以创建一个抽象层，将 kqueue 和 epoll 视为基于完成状态的队列，或者
你可以创建一个抽象层，将 IOCP 视为基于就绪状态的队列。
根据我的个人经验，创建一个模仿基于完成状态的队列的抽象层，并在幕后处理 kqueue 和 epoll 是基于就绪状态的事实，要比反过来容易得多。正如我之前提到的，使用 wepoll 是在 Windows 上创建基于就绪状态的队列的一种方式。这将大大简化创建此类 API 的过程，但我们现在暂时不讨论这一点，因为它不太为人所知，也不是微软官方文档中推荐的方法。

由于 IOCP 是基于完成状态的，它需要一个缓冲区来读取数据，因为它会在数据读取到该缓冲区时返回。而 kqueue 和 epoll 则不需要这样做。它们只会在你可以将数据读取到缓冲区而不会阻塞时返回。

通过要求用户为我们的 API 提供他们首选大小的缓冲区，我们让用户控制他们如何管理内存。用户定义缓冲区的大小，并在使用 IOCP 时控制传递给操作系统的内存的所有方面。



图 3.2 – IOCP 流的简化视图
epoll、kqueue 和 IOCP
epoll 是 Linux 实现事件队列的一种方式。在功能上，它与 kqueue 有很多相似之处。使用 epoll 的优势在于，它被设计得非常高效，可以处理大量事件，而其他类似的方法，例如 select 或 poll，效率相对较低。

kqueue 是 macOS 实现事件队列的一种方式（起源于 BSD），在 FreeBSD 和 OpenBSD 等操作系统中使用。从高层功能上看，它的概念�� epoll 类似，但在实际使用中有所不同。

IOCP 是 Windows 处理此类型事件队列的方式。在 Windows 中，完成端口会在事件完成时通知您。虽然这听起来可能是一个小差异，但实际上并非如此。当您想编写一个库时，这一点尤其明显，因为对这两者的抽象意味着您要么必须将 IOCP 模型化为基于准备的，要么将 epoll/kqueue 模型化为基于完成的。

将缓冲区借给操作系统也带来一些挑战，因为在等待操作返回期间，让这个缓冲区保持不变是非常重要的。

平台	Windows	Linux	macOS
IOCP	epoll	kqueue	
基于完成	基于准备	基于准备	
表 3.1 – 不同平台和事件队列

跨平台事件队列
在创建跨平台事件队列时，您必须处理创建一个统一 API 的事实，该 API 在 Windows（IOCP）、macOS（kqueue）或 Linux（epoll）上使用时都保持一致。最明显的区别是 IOCP 是基于完成的，而 kqueue 和 epoll 是基于准备的。

这种根本的区别意味着您必须做出选择：

您可以创建一个将 kqueue 和 epoll 视为基于完成的队列的抽象，或者
您可以创建一个将 IOCP 视为基于准备的队列的抽象。
根据我的个人经验，创建一个模拟基于完成队列的抽象并在后台处理 kqueue 和 epoll 是基于准备的事实，这要比反过来要容易得多。正如我之前提到的，使用 wepoll 是在 Windows 上创建基于准备的队列的一种方法。这将极大简化创建这样的 API，但我们暂时不讨论这个，因为它较少为人所知，也不是微软官方文档中记录的方法。


由于 IOCP 是基于完成状态的，它需要一个缓冲区来读取数据，因为它会在数据读取到该缓冲区时返回。而 kqueue 和 epoll 则不需要这样做。它们只会在你可以将数据读取到缓冲区而不会阻塞时返回。
通过要求用户为我们的 API 提供他们首选大小的缓冲区，我们让用户控制他们如何管理内存。用户定义缓冲区的大小，并在使用 IOCP 时控制传递给操作系统的内存的所有方面。

在 epoll 和 kqueue 的情况下，对于这样的 API，你可以简单地为用户调用 read 并填充相同的缓冲区，从而让用户感觉 API 是基于完成状态的。
如果你想提供一个基于就绪状态的 API，你必须在 Windows 上进行 I/O 操作时制造一种假象，即有两个独立的操作：首先，请求在套接字上的数据准备好读取时通知你，然后实际读取数据。虽然这是可能的，但你很可能会发现自己需要创建一个非常复杂的 API，或者由于需要中间缓冲区来维持基于就绪状态的 API 的假象，而在 Windows 平台上接受一些效率上的损失。

我们将把事件队列的话题留到后面，当我们创建一个简单的示例来展示它们究竟如何工作时再讨论。在此之前，我们需要真正熟悉 FFI（外部函数接口）和系统调用，我们将通过在三个不同平台上编写一个系统调用的示例来实现这一点。
我们还将利用这个机会讨论抽象层次，以及如何创建一个在三个不同平台上工作的统一 API。

系统调用、FFI 和跨平台抽象
我们将为三种架构实现一个非常基本的系统调用：BSD/macOS、Linux 和 Windows。我们还将看到如何在三个抽象层次上实现这一点。
我们将实现的系统调用是用于向标准输出（stdout）写入内容的调用，因为这是一个非常常见的操作，而且了解它的实际工作原理非常有趣。

我们将从最低层次的抽象开始，逐步构建对系统调用的理解。

最低层次的抽象
最低层次的抽象是编写通常称为“原始”系统调用的代码。原始系统调用绕过了操作系统提供的用于进行系统调用的库，而是依赖于操作系统具有稳定的系统调用 ABI（应用程序二进制接口）。稳定的系统调用 ABI 意味着它保证如果你将正确的数据放入某些寄存器并调用一个特定的 CPU 指令将控制权传递给操作系统，它总是会执行相同的操作。

要进行原始系统调用，我们需要编写一些内联汇编代码，但不用担心。尽管我们在这里突然引入它，但我们将逐行解释，并在第 5 章中更详细地介绍内联汇编，以便你熟悉它。
在这个抽象层次上，我们需要为 BSD/macOS、Linux 和 Windows 编写不同的代码。如果操作系统运行在不同的 CPU 架构上，我们还需要编写不同的代码。

* Raw syscall on Linux
在 Linux 和 macOS 上，我们想要调用的系统调用名为 write。这两个系统都基于文件描述符的概念运行，并且当你启动一个进程时，标准输出（stdout）已经存在。
如果你的机器上没有运行 Linux，你有几种选择来运行这个示例。你可以将代码复制并粘贴到 Rust Playground 中，或者你可以使用 Windows 上的 WSL（Windows Subsystem for Linux）来运行它。

正如在介绍中提到的，我将在每个示例的开头列出你需要跳转到的示例，你可以通过编写 cargo run 来运行该示例。源代码本身始终位于 example 文件夹中的 src/main.rs 文件中。

我们要做的第一件事是引入标准库模块，该模块使我们能够访问 asm! 宏。
仓库参考：ch03/a-raw-syscall

use std::arch::asm;
接下来是编写我们的系统调用函数：

#[inline(never)]
fn syscall(message: String) {
    let msg_ptr = message.as_ptr();
    let len = message.len();
    unsafe {
        asm!(
            "mov rax, 1",
            "mov rdi, 1",
            "syscall",
            in("rsi") msg_ptr,
            in("rdx") len,
            out("rax") _,
            out("rdi") _,
            lateout("rsi") _,
            lateout("rdx") _
        );
    }
}
我们将逐行解释这个函数。接下来的函数会非常相似，所以我们只需要详细解释一次。
首先，我们有一个名为 #[inline(never)] 的属性，它告诉编译器我们永远不希望这个函数在优化过程中被内联。内联是指编译器省略函数调用，而是直接复制函数体。在这种情况下，我们不希望这种情况发生。

接下来是我们的函数调用。函数中的前两行只是获取存储文本的内存位置的原始指针以及文本缓冲区的长度。
下一行是一个 unsafe 块，因为在 Rust 中无法安全地调用这样的汇编代码。

汇编的第一行将值 1 放入 rax 寄存器。当 CPU 稍后捕获我们的调用并将控制权传递给操作系统时，内核知道 rax 中的值为 1 意味着我们想要进行 write 操作。

* Raw syscall on macOS

现在，由于我们使用了特定于 CPU 架构的指令，因此根据你运行的是带有 Intel CPU 的旧款 Mac 还是带有基于 Arm 64 架构 CPU 的新款 Mac，我们需要不同的函数。我们只展示适用于使用 ARM64 架构的新 M 系列芯片的代码，但不用担心，如果你克隆了 Github 仓库，你会在那里找到适用于两种版本 Mac 的代码。

由于只有一些微小的变化，我将在这里展示整个示例，并只讲解其中的差异。
请记住，你需要在带有 macOS 和 M 系列芯片的机器上运行此代码。你无法在 Rust Playground 中尝试此代码。

ch03/a-raw-syscall
use std::arch::asm;

fn main() {
    let message = "Hello world from raw syscall!\n";
    let message = String::from(message);
    syscall(message);
}

#[inline(never)]
fn syscall(message: String) {
    let ptr = message.as_ptr();
    let len = message.len();
    unsafe {
        asm!(
            "mov x16, 4",
            "mov x0, 1",
            "svc 0",
            in("x1") ptr,
            in("x2") len,
            out("x16") _,
            out("x0") _,
            lateout("x1") _,
            lateout("x2") _
        );
    }
}
除了寄存器命名不同之外，这与我们为 Linux 编写的代码没有太大区别，唯一的例外是在 macOS 上，write 操作的代码是 4，而不是 Linux 上的 1。此外，发出软件中断的 CPU 指令是 svc 0，而不是 syscall。

再次强调，如果你在 macOS 上运行此代码，你将在控制台上看到以下输出：

Hello world from raw syscall!
关于 Windows 上的原始系统调用
这是一个很好的机会来解释为什么编写原始系统调用（就像我们刚刚做的那样）是一个坏主意，如果你希望你的程序或库跨平台工作的话。

你看，如果你希望你的代码在未来也能正常工作，你必须担心操作系统提供的保证。例如，Linux 保证写入 rax 寄存器的值 1 将始终引用 write，但 Linux 运行在许多平台上，并不是每个人都使用相同的 CPU 架构。我们在 macOS 上也遇到了同样的问题，它最近从使用基于 Intel 的 x86_64 架构转变为基于 ARM 64 的架构。


Windows 在涉及此类低级内部机制时绝对不提供任何保证。Windows 已经多次更改其内部机制，并且没有提供关于此事的官方文档。我们唯一有的是在互联网上找到的反编译表格，但这些并不是一个可靠的解决方案，因为在你下次运行 Windows 更新时，原本是 write 系统调用的内容可能会被更改为 delete 系统调用。即使这种情况不太可能发生，你也没有任何保证，这反过来使得你无法向你的程序用户保证它在未来能够正常工作。

因此，虽然理论上原始系统调用是有效的，并且熟悉它们是有益的，但它们主要作为一个例子，说明为什么我们更愿意链接到不同操作系统为我们提供的库来进行系统调用。下一节将展示我们如何做到这一点。

下一层抽象
下一层抽象是使用所有三个操作系统为我们提供的 API。我们很快就会发现，这种抽象帮助我们减少了一些代码。在这个特定的例子中，Linux 和 macOS 上的系统调用是相同的，所以我们只需要担心是否在 Windows 上运行。我们可以通过使用 #[cfg(target_family = "windows")] 和 #[cfg(target_family = "unix")] 条件编译标志来区分平台。你将在仓库中的示例中看到这些标志的使用。

我们的 main 函数将看起来与之前相同：

ch03/b-normal-syscall
use std::io;

fn main() {
    let message = "Hello world from syscall!\n";
    let message = String::from(message);
    syscall(message).unwrap();
}
唯一的区别是我们不再引入 asm 模块，而是引入 io 模块。

在 Linux 和 macOS 中使用操作系统提供的 API
你可以在 Rust Playground 中直接运行此代码，因为它运行在 Linux 上，或者你可以在使用 WSL 的 Linux 机器上或 macOS 上本地运行它：

ch03/b-normal-syscall
#[cfg(target_family = "unix")]
#[link(name = "c")]
extern "C" {
    fn write(fd: u32, buf: *const u8, count: usize) -> i32;
}

fn syscall(message: String) -> io::Result<()> {
    let msg_ptr = message.as_ptr();
    let len = message.len();
    let res = unsafe { write(1, msg_ptr, len) };
    if res == -1 {
        return Err(io::Error::last_os_error());
    }
    Ok(())
}
让我们一步一步地了解这些步骤。知道如何正确地进行系统调用将在本书的后续部分对我们非常有用。

#[link(name = "c")]

每个 Linux（和 macOS）系统都附带一个版本的 libc，这是一个用于与操作系统通信的 C 库。拥有 libc 及其一致的 API 使我们能够以相同的方式编程，而无需担心底层平台架构。内核开发者也可以对底层 ABI 进行更改，而不会破坏所有人的程序。这个标志告诉编译器链接到系统上的 “c” 库。

接下来是我们想要调用的链接库中的函数定义：

extern "C" {
    fn write(fd: u32, buf: *const u8, count: usize);
}
extern "C"（有时不写 “C”，因为如果没有指定，“C” 是默认的）意味着我们希望在调用我们链接的 “C” 库中的 write 函数时使用 “C” 调用约定。这个函数需要与我们要链接的库中的函数具有完全相同的名称。参数不必具有相同的名称，但它们必须按相同的顺序排列。最好将它们命名为与你要链接的库中相同的名称。

在这里，我们使用 Rust 的 FFI（外部函数接口），所以当你读到使用 FFI 调用外部函数时，这正是我们在这里所做的。

write 函数接受一个文件描述符 fd，在这种情况下是标准输出的句柄。此外，它期望我们提供一个指向 u8 数组的指针 buf 以及该缓冲区的长度 count。

调用约定
这是我们第一次遇到这个术语，所以我会简要解释一下，尽管我们会在本书的后面深入探讨这个话题。

调用约定定义了如何进行函数调用，并且会指定以下内容：

参数如何传递给函数
函数在开始时预期存储哪些寄存器，并在返回前恢复
函数如何返回其结果
如何设置堆栈（我们稍后会回到这一点）
因此，在调用外部函数之前，你需要指定使用哪种调用约定，因为如果我们不告诉编译器，编译器无法知道。C 调用约定是目前最常见的一种。

接下来，我们将对链接函数的调用包装在一个普通的 Rust 函数中。

ch03/b-normal-syscall
#[cfg(target_family = "unix")]
fn syscall(message: String) -> io::Result<()> {
    let msg_ptr = message.as_ptr();
    let len = message.len();
    let res = unsafe { write(1, msg_ptr, len) };
    if res == -1 {
        return Err(io::Error::last_os_error());
    }
    Ok(())
}
你现在可能已经熟悉前两行了，因为它们与我们编写的原始系统调用示例相同。我们获取存储文本的缓冲区的指针以及该缓冲区的长度。

接下来是对 libc 中的 write 函数的调用，这需要包装在一个 unsafe 块中，因为 Rust 在调用外部函数时无法保证安全性。

你可能会想知道我们如何知道值 1 指的是标准输出的文件句柄。在从 Rust 编写系统调用时，你会经常遇到这种情况。通常，常量在 C 头文件中定义，因此我们需要手动查找这些定义。在 UNIX 系统中，1 始终是标准输出的文件句柄，所以很容易记住。

注意
包装 libc 函数并提供这些常量正是 libc crate（https://github.com/rust-lang/libc）为我们提供的。大多数时候，你可以使用它，而不是像我们在这里那样手动链接和定义函数。

最后，我们有错误处理，你在使用 FFI 时会经常看到这一点。C 函数通常使用特定的整数来指示函数调用是否成功。在这个 write 调用的情况下，函数将返回写入的字节数，或者如果出现错误，则返回值 -1。你可以通过阅读 Linux 的 man 页面（https://man7.org/linux/man-pages/index.html）轻松找到这些信息。

如果出现错误，我们使用 Rust 标准库中的内置函数查询操作系统报告给此进程的最后一个错误，并将其转换为 Rust 的 io::Error 类型。

如果你使用 cargo run 运行此函数，你将看到以下输出：

Hello world from syscall


* using windows api
在 Windows 上，事情的工作方式有些不同。虽然 UNIX 将几乎所有东西都建模为你与之交互的“文件”，但 Windows 使用了其他抽象。在 Windows 上，你会获得一个句柄，该句柄代表你可以以特定方式与之交互的某个对象，具体取决于你拥有的句柄类型。

我们将使用与之前相同的 main 函数，但需要链接到 Windows API 中的不同函数，并对我们的 syscall 函数进行一些更改。

ch03/b-normal-syscall
#[link(name = "kernel32")]
extern "system" {
    fn GetStdHandle(nStdHandle: i32) -> i32;
    fn WriteConsoleW(
        hConsoleOutput: i32,
        lpBuffer: *const u16,
        numberOfCharsToWrite: u32,
        lpNumberOfCharsWritten: *mut u32,
        lpReserved: *const std::ffi::c_void,
    ) -> i32;
}
你首先注意到的是，我们不再链接到 “C” 库，而是链接到 kernel32 库。接下来的变化是使用了 system 调用约定。这个调用约定有点特殊。你看，Windows 根据你是为 32 位 x86 Windows 版本还是 64 位 x86_64 Windows 版本编写代码，使用不同的调用约定。在 x86_64 上运行的较新 Windows 版本使用 “C” 调用约定，因此如果你有一个较新的系统，你可以尝试更改它，看看它是否仍然有效。“指定 system”让编译器根据系统确定要使用的正确调用约定。

我们在 Windows 中链接了两个不同的系统调用：

GetStdHandle：获取对标准设备（如标准输出）的引用。
WriteConsoleW：WriteConsole 有两种类型。WriteConsoleW 接受 Unicode 文本，而 WriteConsoleA 接受 ANSI 编码的文本。我们在程序中使用的是接受 Unicode 文本的那个。
现在，如果你只写英文文本，ANSI 编码的文本可以正常工作，但一旦你写其他语言的文本，你可能需要使用 ANSI 中无法表示但在 Unicode 中可以表示的特殊字符。如果你混淆了它们，你的程序将不会按预期工作。

接下来是我们的新 syscall 函数：

ch03/b-normal-syscall
fn syscall(message: String) -> io::Result<()> {
    let msg: Vec<u16> = message.encode_utf16().collect();
    let msg_ptr = msg.as_ptr();
    let len = msg.len() as u32;
    let mut output: u32 = 0;
    let handle = unsafe { GetStdHandle(-11) };
    if handle == -1 {
        return Err(io::Error::last_os_error());
    }
    let res = unsafe {
        WriteConsoleW(
            handle,
            msg_ptr,
            len,
            &mut output,
            std::ptr::null()
        )
    };
    if res == 0 {
        return Err(io::Error::last_os_error());
    }
    Ok(())
}
我们做的第一件事是将文本转换为 Windows 使用的 utf-16 编码文本。幸运的是，Rust 有一个内置函数可以将我们的 utf-8 编码文本转换为 utf-16 代码点。encode_utf16 返回一个 u16 代码点的迭代器，我们可以将其收集到一个 Vec 中。


接下来的两行现在应该很熟悉了。我们获取存储文本的指针以及文本的字节长度。接下来，我们调用 GetStdHandle 并传入值 -11。我们需要为不同的标准设备传入的值在 GetStdHandle 文档中有详细描述，文档地址为：https://learn.microsoft.com/en-us/windows/console/getstdhandle。这很方便，因为我们不需要翻阅 C 头文件来查找所有需要的常量值。

所有函数的返回代码也有详细的文档记录，因此我们在这里处理潜在错误的方式与处理 Linux/macOS 系统调用的方式相同。

最后，我们调用 WriteConsoleW 函数。这并没有什么特别复杂的地方，你会注意到它与我们在 Linux 上使用的 write 系统调用有相似之处。一个区别是输出不是从函数返回的，而是写入我们以指针形式传入的输出变量地址。

注意
现在你已经看到了我们如何创建跨平台的系统调用，你可能也会理解为什么我们没有在本书中为每个示例都包含跨平台代码。如果这样做，这本书会变得非常长，而且并不明显所有这些额外的信息是否真的有助于我们理解关键概念。

最高层次的抽象
这很简单，但我想为了完整性而添加这一点。Rust 标准库为我们封装了对底层操作系统 API 的调用，因此我们不需要关心要调用哪些系统调用。

fn main() {
    println!("Hello world from the standard library");
}
恭喜！你现在已经使用三种抽象层次编写了相同的系统调用。你现在知道 FFI 是什么样子了，你已经看到了一些内联汇编（我们稍后会详细讨论），并且你已经正确地调用了系统调用来将内容打印到控制台。你还看到了标准库试图通过为不同平台封装这些调用来解决的问题之一，这样我们就不需要知道这些系统调用来将内容打印到控制台。

总结
在本章中，我们介绍了操作系统支持的事件队列是什么，并对其工作原理进行了高层次的概述。我们还讨论了 epoll、kqueue 和 IOCP 的定义特征，并重点介绍了它们之间的区别。

 

在本章的后半部分，我们介绍了一些系统调用的示例。我们讨论了原始系统调用和“普通”系统调用，以便你知道它们是什么，并看到了两者的示例。我们还借此机会讨论了抽象层次以及在我们能够使用良好抽象时依赖它们的好处。

作为系统调用的一部分，你还初步了解了 Rust 的 FFI（外部函数接口）。

最后，我们创建了一个跨平台的抽象。你也看到了创建一个适用于多个操作系统的统一 API 所带来的一些挑战。

下一章将带你通过一个使用 epoll 创建简单事件队列的示例，这样你就可以确切地看到它在实践中是如何工作的。在代码仓库中，你还可以找到适用于 Windows 和 macOS 的相同示例，因此如果你曾想为这两个平台中的任何一个实现事件队列，你都可以参考这些示例。



# Part 2:Event Queues and Green Threads 第二部分：事件队列和绿色线程




    
